# ğŸµ è¯­éŸ³å¤„ç†å¥—ä»¶ (Voice Processing Suite)

> **åŸºäºä¿¡å·ä¸ç³»ç»Ÿç†è®ºçš„ç°ä»£åŒ–è¯­éŸ³å¤„ç†ç³»ç»Ÿ**  
> é›†æˆéŸ³é¢‘é¢„å¤„ç†ã€éŸ³æºåˆ†ç¦»ã€è¯´è¯äººè¯†åˆ«ä¸è¯­éŸ³åŒ¹é…çš„å®Œæ•´è§£å†³æ–¹æ¡ˆ

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://www.python.org/)
[![PyQt6](https://img.shields.io/badge/PyQt6-6.5+-green.svg)](https://pypi.org/project/PyQt6/)
[![Signal Processing](https://img.shields.io/badge/Signal_Processing-DSP-red.svg)](README.md)
[![Status](https://img.shields.io/badge/Status-Production%20Ready-brightgreen.svg)](README.md)

## ğŸš€ é¡¹ç›®äº®ç‚¹

- ğŸ¯ **å®Œæ•´çš„è¯­éŸ³å¤„ç†ç®¡é“**ï¼šä»æ··åˆéŸ³é¢‘åˆ°ç›®æ ‡è¯­éŸ³çš„ç«¯åˆ°ç«¯å¤„ç†
- ğŸ”¬ **ä¿¡å·å¤„ç†ç†è®ºåº”ç”¨**ï¼šFFTã€æ»¤æ³¢å™¨è®¾è®¡ã€é¢‘åŸŸåˆ†æç­‰ç»å…¸ç†è®ºå®ç°
- ğŸ¤– **æ·±åº¦å­¦ä¹ é›†æˆ**ï¼šç»“åˆ Demucsã€Pyannote ç­‰å…ˆè¿›æ¨¡å‹
- ğŸ–¥ï¸ **ç°ä»£åŒ– GUI ç•Œé¢**ï¼šPyQt6 å¼€å‘çš„ä¸“ä¸šçº§ç”¨æˆ·ç•Œé¢
- ğŸ“Š **å®æ—¶å¯è§†åŒ–**ï¼šå†…ç½®é¢‘è°±åˆ†æã€æ³¢å½¢æ˜¾ç¤ºç­‰å¯è§†åŒ–å·¥å…·
- ğŸ“ **æ•™å­¦å‹å¥½**ï¼šé€‚åˆä¿¡å·ä¸ç³»ç»Ÿè¯¾ç¨‹çš„å®è·µæ•™å­¦å’Œæ¼”ç¤º

## ğŸ“‹ ç›®å½•

- [é¡¹ç›®äº®ç‚¹](#-é¡¹ç›®äº®ç‚¹)
- [ç³»ç»Ÿæ¦‚è¿°](#-ç³»ç»Ÿæ¦‚è¿°)
- [æ ¸å¿ƒåŠŸèƒ½](#-æ ¸å¿ƒåŠŸèƒ½)
- [æŠ€æœ¯æ¶æ„](#-æŠ€æœ¯æ¶æ„)
- [å®‰è£…æŒ‡å—](#-å®‰è£…æŒ‡å—)
- [å¿«é€Ÿå¼€å§‹](#-å¿«é€Ÿå¼€å§‹)
- [ä½¿ç”¨æ•™ç¨‹](#-ä½¿ç”¨æ•™ç¨‹)
- [API å‚è€ƒ](#-apiå‚è€ƒ)
- [æŠ€æœ¯ç»†èŠ‚](#-æŠ€æœ¯ç»†èŠ‚)
- [æ•…éšœæ’é™¤](#-æ•…éšœæ’é™¤)
- [é¡¹ç›®ç»“æ„](#-é¡¹ç›®ç»“æ„)
- [è´¡çŒ®æŒ‡å—](#-è´¡çŒ®æŒ‡å—)
- [è®¸å¯è¯](#-è®¸å¯è¯)

## ğŸŒŸ ç³»ç»Ÿæ¦‚è¿°

è¯­éŸ³å¤„ç†å¥—ä»¶æ˜¯ä¸€ä¸ªä¸“ä¸º**ä¿¡å·ä¸ç³»ç»Ÿè¯¾ç¨‹**è®¾è®¡çš„ç»¼åˆæ€§è¯­éŸ³å¤„ç†ç³»ç»Ÿï¼Œå±•ç¤ºäº†ç°ä»£æ•°å­—ä¿¡å·å¤„ç†æŠ€æœ¯åœ¨å®é™…å·¥ç¨‹ä¸­çš„åº”ç”¨ã€‚ç³»ç»Ÿèƒ½å¤Ÿä»å¤æ‚çš„æ··åˆéŸ³é¢‘ç¯å¢ƒä¸­å‡†ç¡®æå–å’Œè¯†åˆ«ç›®æ ‡è¯´è¯äººçš„è¯­éŸ³ã€‚

### ğŸ¯ æ ¸å¿ƒåº”ç”¨åœºæ™¯

- **ğŸ“š æ•™è‚²æ•™å­¦**ï¼šä¿¡å·ä¸ç³»ç»Ÿç†è®ºçš„å®è·µæ¼”ç¤ºå¹³å°
- **ğŸ™ï¸ ä¼šè®®å¤„ç†**ï¼šå¤šäººä¼šè®®å½•éŸ³ä¸­çš„ä¸ªäººå‘è¨€æå–
- **ğŸµ å†…å®¹åˆ¶ä½œ**ï¼šæ’­å®¢ã€è®¿è°ˆç­‰éŸ³é¢‘å†…å®¹çš„åæœŸå¤„ç†
- **ğŸ” éŸ³é¢‘åˆ†æ**ï¼šè¯­éŸ³ç‰¹å¾åˆ†æå’Œè¯´è¯äººè¯†åˆ«ç ”ç©¶
- **ğŸ› ï¸ å·¥ç¨‹åº”ç”¨**ï¼šå®é™…è¯­éŸ³å¤„ç†é¡¹ç›®çš„æŠ€æœ¯éªŒè¯

### ğŸ’¡ æŠ€æœ¯åˆ›æ–°

- **ğŸ”„ å¤šçº§å¤„ç†æ¶æ„**ï¼šç²—åˆ†ç¦» â†’ ç»†åˆ†ç¦» â†’ ç‰¹å¾åŒ¹é…çš„å±‚æ¬¡åŒ–å¤„ç†æµç¨‹
- **ğŸ›ï¸ è‡ªé€‚åº”å‚æ•°è°ƒæ•´**ï¼šæ ¹æ®éŸ³é¢‘ç‰¹æ€§åŠ¨æ€ä¼˜åŒ–å¤„ç†å‚æ•°
- **ğŸ”— å¤šç‰¹å¾èåˆ**ï¼šMFCCã€è°±ç‰¹å¾ã€æ—¶åŸŸç‰¹å¾çš„ç»¼åˆåˆ†æ
- **âš¡ å®æ—¶å¤„ç†èƒ½åŠ›**ï¼šæ”¯æŒæµå¼å¤„ç†å’Œæ‰¹é‡å¤„ç†æ¨¡å¼
- **ğŸ¨ ç°ä»£åŒ–ç•Œé¢**ï¼šç›´è§‚çš„æ“ä½œç•Œé¢å’Œä¸°å¯Œçš„å¯è§†åŒ–å±•ç¤º

## ğŸ”§ æ ¸å¿ƒåŠŸèƒ½

### ğŸšï¸ éŸ³é¢‘é¢„å¤„ç†æ¨¡å—

åŸºäºæ•°å­—ä¿¡å·å¤„ç†ç†è®ºçš„å…ˆè¿›éŸ³é¢‘é¢„å¤„ç†ç³»ç»Ÿï¼š

- **ğŸ“Š FFT é¢‘åŸŸåˆ†æ**ï¼šå®Œæ•´çš„é¢‘è°±åˆ†æå’Œèƒ½é‡åˆ†å¸ƒå¯è§†åŒ–
- **ğŸ”ˆ å¸¦é€šæ»¤æ³¢å™¨**ï¼šå·´ç‰¹æ²ƒæ–¯æ»¤æ³¢å™¨å®ç°è¯­éŸ³é¢‘æ®µåˆ†ç¦»(80Hz-8kHz)
- **ğŸ”‡ è°±å‡æ³•é™å™ª**ï¼šç»å…¸è°±å‡ç®—æ³•å®ç°èƒŒæ™¯å™ªå£°æŠ‘åˆ¶
- **âš¡ ç»´çº³æ»¤æ³¢**ï¼šåŸºäºä¿¡å™ªæ¯”çš„æœ€ä¼˜ä¿¡å·å¢å¼º
- **ğŸ“ˆ å®æ—¶å¯è§†åŒ–**ï¼šæ—¶åŸŸã€é¢‘åŸŸã€æ—¶é¢‘å›¾çš„åŠ¨æ€æ˜¾ç¤º

**æŠ€æœ¯ç‰¹ç‚¹**ï¼š

```python
# æ ¸å¿ƒæ»¤æ³¢å™¨è®¾è®¡ç¤ºä¾‹
def design_butterworth_filter(low_freq, high_freq, sample_rate, order=4):
    nyquist = sample_rate / 2
    low_normalized = low_freq / nyquist
    high_normalized = high_freq / nyquist
    sos = butter(order, [low_normalized, high_normalized],
                btype='band', output='sos')
    return sos
```

### ğŸ¼ éŸ³æºåˆ†ç¦»æ¨¡å—

ä¸“ä¸šçº§éŸ³ä¹æºåˆ†ç¦»æŠ€æœ¯ï¼š

- **ğŸ¤– Demucs é›†æˆ**ï¼šæœ€æ–° HTDemucs æ¨¡å‹ï¼Œå“è¶Šçš„åˆ†ç¦»è´¨é‡
- **ğŸµ å¤šéŸ³è½¨è¾“å‡º**ï¼šäººå£°ã€é¼“å£°ã€è´æ–¯ã€å…¶ä»–ä¹å™¨çš„ç‹¬ç«‹åˆ†ç¦»
- **âš™ï¸ æ¨¡å‹ç®¡ç†**ï¼šè‡ªåŠ¨ä¸‹è½½ã€ç¼“å­˜å’Œç‰ˆæœ¬ç®¡ç†
- **ğŸ“‹ è´¨é‡è¯„ä¼°**ï¼šå…¨é¢çš„åˆ†ç¦»è´¨é‡æŒ‡æ ‡å’Œè¯¦ç»†æŠ¥å‘Š
- **ğŸ”§ çµæ´»é…ç½®**ï¼šæ”¯æŒ CPU/GPU åˆ‡æ¢å’Œè‡ªå®šä¹‰å‚æ•°

**åˆ†ç¦»æ•ˆæœ**ï¼š

- äººå£°åˆ†ç¦»è´¨é‡ï¼šSINR æå‡ 15-25dB
- å¤„ç†é€Ÿåº¦ï¼šå®æ—¶ç³»æ•° 0.1-0.3ï¼ˆCPU æ¨¡å¼ï¼‰
- æ”¯æŒæ ¼å¼ï¼šWAV, MP3, FLAC, M4A, AAC

### ğŸ‘¥ è¯´è¯äººåˆ†ç¦»æ¨¡å—

å…ˆè¿›çš„è¯´è¯äººè¯†åˆ«å’Œåˆ†ç¦»æŠ€æœ¯ï¼š

- **ğŸ¯ Pyannote é›†æˆ**ï¼šåŸºäºç¥ç»ç½‘ç»œçš„è¯´è¯äººæ—¶é—´è½´åˆ†æ
- **ğŸ” è‡ªåŠ¨è®¤è¯**ï¼šæ— ç¼ Hugging Face Hub é›†æˆå’Œèº«ä»½éªŒè¯
- **ğŸ“… æ—¶é—´è½´åˆ†æ**ï¼šè¯¦ç»†çš„è¯´è¯äººé‡å æ£€æµ‹å’Œæ—¶é—´æ ‡è®°
- **ğŸ“„ RTTM è¾“å‡º**ï¼šæ ‡å‡†åŒ–çš„è¯´è¯äººæ ‡æ³¨æ–‡ä»¶æ ¼å¼

**æŠ€æœ¯æŒ‡æ ‡**ï¼š

- è¯´è¯äººæ£€æµ‹å‡†ç¡®ç‡ï¼š>90%ï¼ˆæ¸…æ™°è¯­éŸ³æ¡ä»¶ï¼‰
- æ”¯æŒè¯´è¯äººæ•°é‡ï¼š2-10 äººï¼ˆæ¨è 2-5 äººï¼‰
- æœ€çŸ­è¯­éŸ³æ®µï¼š0.5 ç§’

### ğŸ¯ è¯­éŸ³åŒ¹é…æ¨¡å—

å¤šç»´ç‰¹å¾èåˆçš„è¯­éŸ³è¯†åˆ«åŒ¹é…ï¼š

- **ğŸ” å¤šç‰¹å¾åˆ†æ**ï¼šMFCCã€æ¢…å°”é¢‘è°±ã€è°±ç‰¹å¾ã€æ—¶åŸŸç‰¹å¾
- **ğŸ“Š é«˜çº§ç›¸ä¼¼åº¦ç®—æ³•**ï¼šä½™å¼¦ç›¸ä¼¼åº¦ã€çš®å°”é€Šç›¸å…³ã€ç»„åˆè¯„åˆ†
- **ğŸ¯ å‚è€ƒåŒ¹é…**ï¼šåŸºäºå‚è€ƒéŸ³é¢‘çš„æœ€ä½³åŒ¹é…æŸ¥æ‰¾
- **ğŸ“ˆ å¯è§†åŒ–æŠ¥å‘Š**ï¼šè¯¦ç»†çš„ç›¸ä¼¼åº¦åˆ†æå’Œç‰¹å¾å¯¹æ¯”å›¾è¡¨

**ç‰¹å¾æå–æŠ€æœ¯**ï¼š

```python
# MFCCç‰¹å¾æå–ç¤ºä¾‹
mfcc_features = librosa.feature.mfcc(
    y=audio, sr=sample_rate, n_mfcc=13,
    hop_length=256, n_fft=1024
)
delta_mfcc = librosa.feature.delta(mfcc_features)
delta2_mfcc = librosa.feature.delta(mfcc_features, order=2)
```

### ğŸ–¥ï¸ ç°ä»£åŒ– GUI åº”ç”¨

ä¸“ä¸šçº§æ¡Œé¢åº”ç”¨ç•Œé¢ï¼š

- **ğŸ´ å››æ¨¡å—è®¾è®¡**ï¼šç‹¬ç«‹çš„å¤„ç†å¡ç‰‡ï¼Œæ¸…æ™°çš„åŠŸèƒ½åˆ†ç¦»
- **ğŸ“Š è¿›åº¦è¿½è¸ª**ï¼šå®æ—¶è¿›åº¦æŒ‡ç¤ºå™¨å’ŒçŠ¶æ€æ›´æ–°
- **ğŸ’» æ§åˆ¶å°é›†æˆ**ï¼šå®æ—¶æ§åˆ¶å°è¾“å‡ºé‡å®šå‘å’Œæ—¥å¿—è®°å½•
- **ğŸ“ˆ äº¤äº’å¼å¯è§†åŒ–**ï¼šé›†æˆ Matplotlib çš„å®æ—¶å›¾è¡¨æ˜¾ç¤º
- **ğŸ¨ ç°ä»£è®¾è®¡**ï¼šæ¯›ç»ç’ƒæ•ˆæœã€æ¸å˜èƒŒæ™¯ã€æµç•…åŠ¨ç”»
- **ğŸŒ ä¸­æ–‡ç•Œé¢**ï¼šå®Œå…¨ä¸­æ–‡åŒ–çš„ç”¨æˆ·å‹å¥½ç•Œé¢

**ç•Œé¢ç‰¹è‰²**ï¼š

- å®æ—¶æ³¢å½¢å’Œé¢‘è°±æ˜¾ç¤º
- æ‹–æ‹½å¼æ–‡ä»¶é€‰æ‹©
- ä¸€é”®æŸ¥çœ‹ç»“æœå’ŒæŠ¥å‘Š
- è‡ªåŠ¨é”™è¯¯æ£€æµ‹å’Œæ¢å¤å»ºè®®

## ğŸ—ï¸ æŠ€æœ¯æ¶æ„

### ğŸ”„ ç³»ç»Ÿå¤„ç†æµç¨‹

```mermaid
graph TD
    A[ğŸ¤ æ··åˆéŸ³é¢‘è¾“å…¥] --> B[ğŸšï¸ éŸ³é¢‘é¢„å¤„ç†]
    B --> C[ğŸ¼ DemucséŸ³æºåˆ†ç¦»]
    C --> D[ğŸ‘¥ Pyannoteè¯´è¯äººåˆ†ç¦»]
    D --> E[ğŸ¯ MFCCç‰¹å¾åŒ¹é…]
    E --> F[ğŸµ ç›®æ ‡è¯­éŸ³è¾“å‡º]

    G[ğŸ“Š å®æ—¶å¯è§†åŒ–] --> H[ğŸ“ˆ æ³¢å½¢æ˜¾ç¤º]
    G --> I[ğŸ”Š é¢‘è°±åˆ†æ]
    G --> J[ğŸ›ï¸ æ»¤æ³¢å™¨å“åº”]
    G --> K[ğŸŒˆ æ—¶é¢‘å›¾]

    L[ğŸ¯ å‚è€ƒéŸ³é¢‘] --> E
    M[âš™ï¸ å‚æ•°é…ç½®] --> B
    M --> C
    M --> D
    M --> E
```

### ğŸ“ é¡¹ç›®ç»“æ„

```
voice_processing/
â”œâ”€â”€ ğŸ“± main.py                      # ğŸš€ ç¨‹åºå…¥å£ç‚¹
â”œâ”€â”€ ğŸ“‹ requirements.txt             # ğŸ“¦ ä¾èµ–åŒ…é…ç½®
â”œâ”€â”€ âš™ï¸ setup.py                     # ğŸ› ï¸ å®‰è£…é…ç½®
â”œâ”€â”€ ğŸ“– PROJECT_OVERVIEW.md          # ğŸ“š é¡¹ç›®è¯¦ç»†ä»‹ç»
â”‚
â”œâ”€â”€ ğŸ¨ gui/                         # ğŸ–¥ï¸ ç”¨æˆ·ç•Œé¢å±‚
â”‚   â”œâ”€â”€ voice_processing_app.py     # ğŸ  ä¸»åº”ç”¨ç¨‹åº
â”‚   â”œâ”€â”€ modern_voice_app.py         # âœ¨ ç°ä»£åŒ–ç•Œé¢ç‰ˆæœ¬
â”‚   â”œâ”€â”€ modern_style.qss            # ğŸ¨ ç•Œé¢æ ·å¼è¡¨
â”‚   â””â”€â”€ README_GUI_IMPROVEMENTS.md  # ğŸ“ ç•Œé¢æ”¹è¿›è¯´æ˜
â”‚
â”œâ”€â”€ ğŸ”§ modules/                     # ğŸ› ï¸ æ ¸å¿ƒå¤„ç†æ¨¡å—
â”‚   â”œâ”€â”€ preprocessing/              # ğŸšï¸ éŸ³é¢‘é¢„å¤„ç†
â”‚   â”‚   â””â”€â”€ audio_preprocessor.py   # ğŸ“Š FFTåˆ†æã€æ»¤æ³¢å™¨è®¾è®¡
â”‚   â”œâ”€â”€ source_separation/          # ğŸ¼ éŸ³æºåˆ†ç¦»
â”‚   â”‚   â””â”€â”€ demucs_separator.py     # ğŸ¤– Demucsæ¨¡å‹é›†æˆ
â”‚   â”œâ”€â”€ speaker_separation/         # ğŸ‘¥ è¯´è¯äººåˆ†ç¦»
â”‚   â”‚   â””â”€â”€ speaker_separator.py    # ğŸ¯ Pyannoteæ—¶é—´è½´åˆ†æ
â”‚   â”œâ”€â”€ voice_matching/             # ğŸ” è¯­éŸ³åŒ¹é…
â”‚   â”‚   â””â”€â”€ voice_matcher.py        # ğŸ“ˆ MFCCç‰¹å¾åŒ¹é…
â”‚   â””â”€â”€ utils/                      # ğŸ”¨ å·¥å…·å‡½æ•°
â”‚       â”œâ”€â”€ audio_utils.py          # ğŸµ éŸ³é¢‘å¤„ç†å·¥å…·
â”‚       â””â”€â”€ audio_converter.py      # ğŸ”„ æ ¼å¼è½¬æ¢å·¥å…·
â”‚
â”œâ”€â”€ ğŸ”„ core/                        # ğŸ§  æ ¸å¿ƒå¤„ç†é€»è¾‘
â”‚   â””â”€â”€ process_pipeline.py         # ğŸ›¤ï¸ å®Œæ•´å¤„ç†ç®¡é“
â”‚
â”œâ”€â”€ ğŸ“‚ input/                       # ğŸ“¥ è¾“å…¥éŸ³é¢‘ç›®å½•
â”œâ”€â”€ ğŸ¯ reference/                   # ğŸ“š å‚è€ƒéŸ³é¢‘ç›®å½•
â”œâ”€â”€ ğŸ“¤ output/                      # ğŸ“ å¤„ç†ç»“æœç›®å½•
â”‚   â”œâ”€â”€ preprocessing/              # ğŸšï¸ é¢„å¤„ç†ç»“æœ
â”‚   â”œâ”€â”€ demucs_output/             # ğŸ¼ éŸ³æºåˆ†ç¦»ç»“æœ
â”‚   â”œâ”€â”€ speaker_output/            # ğŸ‘¥ è¯´è¯äººåˆ†ç¦»ç»“æœ
â”‚   â””â”€â”€ final_output/              # ğŸ¯ æœ€ç»ˆåŒ¹é…ç»“æœ
â”‚
â”œâ”€â”€ ğŸ—‚ï¸ temp/                        # ğŸ’¾ ä¸´æ—¶æ–‡ä»¶ç›®å½•
â”œâ”€â”€ ğŸ“Š logs/                        # ğŸ“‹ æ—¥å¿—æ–‡ä»¶ç›®å½•
â””â”€â”€ ğŸµ voice_processing_pipeline.py  # ğŸš€ å®Œæ•´ç®¡é“è„šæœ¬
```

### ğŸ§© æ ¸å¿ƒç±»è®¾è®¡

#### ğŸ›¤ï¸ VoiceProcessingPipeline - ä¸»å¤„ç†ç®¡é“

```python
class VoiceProcessingPipeline:
    """å®Œæ•´çš„è¯­éŸ³å¤„ç†ç®¡é“"""

    def __init__(self, config=None, hf_token=None):
        self.preprocessor = AudioPreprocessor(sample_rate=16000)
        self.source_separator = DemucsSourceSeparator(model_name="htdemucs")
        self.speaker_separator = SpeakerSeparator(hf_token=hf_token)
        self.voice_matcher = VoiceMatcher(sample_rate=16000)

    def run_complete_pipeline(self, input_path, reference_path):
        """æ‰§è¡Œå®Œæ•´çš„å¤„ç†æµç¨‹"""
        # 1. éŸ³é¢‘é¢„å¤„ç†
        preprocess_results = self.run_preprocessing(input_path)

        # 2. éŸ³æºåˆ†ç¦»
        separation_results = self.run_source_separation(
            preprocess_results['output_path']
        )

        # 3. è¯´è¯äººåˆ†ç¦»
        speaker_results = self.run_speaker_separation(
            separation_results['separated_files']['vocals']
        )

        # 4. è¯­éŸ³åŒ¹é…
        matching_results = self.run_voice_matching(
            reference_path, speaker_results['separated_files']
        )

        return matching_results
```

#### ğŸšï¸ AudioPreprocessor - éŸ³é¢‘é¢„å¤„ç†å™¨

```python
class AudioPreprocessor:
    """åŸºäºDSPç†è®ºçš„éŸ³é¢‘é¢„å¤„ç†å™¨"""

    def process_audio(self, input_path, output_dir, **kwargs):
        """å®Œæ•´çš„é¢„å¤„ç†æµç¨‹"""
        # åŠ è½½éŸ³é¢‘
        audio = self.load_audio(input_path)

        # FFTé¢‘åŸŸåˆ†æ
        spectrum = self.analyze_frequency_domain(audio)

        # å¸¦é€šæ»¤æ³¢
        if kwargs.get('apply_bandpass', True):
            audio = self.apply_bandpass_filter(
                audio, kwargs.get('low_freq', 80),
                kwargs.get('high_freq', 8000)
            )

        # è°±å‡æ³•é™å™ª
        if kwargs.get('apply_spectral_subtraction', True):
            audio = self.spectral_subtraction(audio)

        # ç»´çº³æ»¤æ³¢
        if kwargs.get('apply_wiener', False):
            audio = self.wiener_filter(audio)

        return self.save_results(audio, output_dir)
```

### ğŸ”„ æ•°æ®æµæ¶æ„

```mermaid
sequenceDiagram
    participant User as ğŸ‘¤ ç”¨æˆ·
    participant GUI as ğŸ–¥ï¸ GUIç•Œé¢
    participant Pipeline as ğŸ›¤ï¸ å¤„ç†ç®¡é“
    participant Modules as ğŸ”§ å¤„ç†æ¨¡å—
    participant Storage as ğŸ’¾ å­˜å‚¨ç³»ç»Ÿ

    User->>GUI: ğŸ“ é€‰æ‹©éŸ³é¢‘æ–‡ä»¶
    GUI->>Pipeline: ğŸš€ å¯åŠ¨å¤„ç†æµç¨‹
    Pipeline->>Modules: ğŸšï¸ éŸ³é¢‘é¢„å¤„ç†
    Modules->>Storage: ğŸ’¾ ä¿å­˜ä¸­é—´ç»“æœ
    Pipeline->>Modules: ğŸ¼ éŸ³æºåˆ†ç¦»
    Modules->>Storage: ğŸ’¾ ä¿å­˜åˆ†ç¦»ç»“æœ
    Pipeline->>Modules: ğŸ‘¥ è¯´è¯äººåˆ†ç¦»
    Modules->>Storage: ğŸ’¾ ä¿å­˜è¯´è¯äººéŸ³é¢‘
    Pipeline->>Modules: ğŸ¯ è¯­éŸ³åŒ¹é…
    Modules->>Storage: ğŸ’¾ ä¿å­˜æœ€ç»ˆç»“æœ
    Pipeline->>GUI: âœ… è¿”å›å¤„ç†ç»“æœ
    GUI->>User: ğŸ“Š æ˜¾ç¤ºç»“æœæŠ¥å‘Š
```

## ğŸ“¦ å®‰è£…æŒ‡å—

### ğŸ”§ ç³»ç»Ÿè¦æ±‚

- **ğŸ–¥ï¸ æ“ä½œç³»ç»Ÿ**ï¼šWindows 10/11, macOS 10.15+, Ubuntu 18.04+
- **ğŸ Python ç‰ˆæœ¬**ï¼š3.10 æˆ–æ›´é«˜ç‰ˆæœ¬
- **ğŸ’¾ å†…å­˜è¦æ±‚**ï¼š8GB RAM æœ€ä½ (æ¨è 16GB)
- **ğŸ’½ å­˜å‚¨ç©ºé—´**ï¼š10GB å¯ç”¨ç©ºé—´ï¼ˆåŒ…å«æ¨¡å‹å’Œå¤„ç†æ–‡ä»¶ï¼‰
- **ğŸš€ GPU æ”¯æŒ**ï¼šå¯é€‰ (CUDA å…¼å®¹ GPU å¯åŠ é€Ÿå¤„ç†)

### âš¡ å¿«é€Ÿå®‰è£…

#### 1ï¸âƒ£ å…‹éš†é¡¹ç›®

```bash
git clone https://github.com/your-repo/voice-processing-suite.git
cd voice-processing-suite
```

#### 2ï¸âƒ£ åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
# ä½¿ç”¨ conda (æ¨è)
conda create -n voice_processing python=3.10
conda activate voice_processing

# æˆ–ä½¿ç”¨ venv
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/macOS
source venv/bin/activate
```

#### 3ï¸âƒ£ å®‰è£… PyTorch (GPU åŠ é€Ÿæ¨è)

**ğŸªŸ Windows ç³»ç»Ÿï¼š**

```bash
install_pytorch.bat
```

**ğŸ§ Linux/macOS ç³»ç»Ÿï¼š**

```bash
bash install_pytorch.sh
```

**ğŸ”§ æ‰‹åŠ¨å®‰è£…ï¼š**

```bash
# GPUç‰ˆæœ¬ (CUDA 12.1)
pip install torch==2.2.2+cu121 torchaudio==2.2.2+cu121 --index-url https://download.pytorch.org/whl/cu121

# CPUç‰ˆæœ¬
pip install torch==2.2.2 torchaudio==2.2.2 --index-url https://download.pytorch.org/whl/cpu

# å®‰è£…é¡¹ç›®ä¾èµ–
pip install -r requirements.txt
```

#### 4ï¸âƒ£ éªŒè¯å®‰è£…

```bash
# ç³»ç»Ÿæµ‹è¯•
python test_system.py

# å¯åŠ¨GUIåº”ç”¨
python main.py
```

#### 5ï¸âƒ£ æ¨¡å‹å‡†å¤‡ (è‡ªåŠ¨ä¸‹è½½)

```bash
# Demucsæ¨¡å‹å°†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶è‡ªåŠ¨ä¸‹è½½
python -c "import demucs; print('âœ… Demucs å‡†å¤‡å°±ç»ª')"

# è®¾ç½®Hugging Faceè®¿é—®ä»¤ç‰Œ (ç”¨äºè¯´è¯äººåˆ†ç¦»)
export HF_TOKEN="your_huggingface_token"
```

### ğŸ³ Docker éƒ¨ç½² (é«˜çº§ç”¨æˆ·)

```dockerfile
FROM python:3.10-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 8080
CMD ["python", "main.py"]
```

```bash
# æ„å»ºé•œåƒ
docker build -t voice-processing .

# è¿è¡Œå®¹å™¨
docker run -it --rm \
    -v $(pwd)/input:/app/input \
    -v $(pwd)/output:/app/output \
    voice-processing
```

### âš ï¸ å¸¸è§é—®é¢˜è§£å†³

#### ğŸ”§ PyTorch å®‰è£…é—®é¢˜

```bash
# CUDAç‰ˆæœ¬ä¸å…¼å®¹æ—¶ï¼Œä½¿ç”¨CPUç‰ˆæœ¬
pip uninstall torch torchaudio
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cpu
```

#### ğŸµ éŸ³é¢‘åº“ä¾èµ–é—®é¢˜

```bash
# Ubuntu/Debian
sudo apt-get update
sudo apt-get install libsndfile1 ffmpeg

# macOS
brew install libsndfile ffmpeg

# Windows (ä½¿ç”¨conda)
conda install -c conda-forge libsndfile ffmpeg
```

#### ğŸ”‘ æƒé™å’Œè®¤è¯é—®é¢˜

```bash
# è®¾ç½®HF Tokenç¯å¢ƒå˜é‡
# Windows
set HF_TOKEN=your_token_here

# Linux/macOS
export HF_TOKEN="your_token_here"

# æˆ–åœ¨ä»£ç ä¸­ç›´æ¥è®¾ç½®
# ä¿®æ”¹ gui/voice_processing_app.py ä¸­çš„ hf_token å˜é‡
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ğŸ–¥ï¸ ä½¿ç”¨ GUI åº”ç”¨ç¨‹åº

#### å¯åŠ¨åº”ç”¨

```bash
# æ–¹å¼1ï¼šç›´æ¥å¯åŠ¨
python main.py

# æ–¹å¼2ï¼šé€šè¿‡GUIæ¨¡å—å¯åŠ¨
python gui/voice_processing_app.py

# æ–¹å¼3ï¼šä½¿ç”¨ç°ä»£åŒ–ç•Œé¢
python gui/modern_voice_app.py
```

#### ğŸ“‹ å®Œæ•´å¤„ç†æµç¨‹

**ğŸ¯ å››æ­¥å¤„ç†å·¥ä½œæµ**ï¼š

1. **ğŸšï¸ éŸ³é¢‘é¢„å¤„ç†**

   - ğŸ“ é€‰æ‹©æ··åˆéŸ³é¢‘æ–‡ä»¶ â†’ ç‚¹å‡»"ğŸš€ å¼€å§‹å¤„ç†"
   - ğŸ“Š æŸ¥çœ‹é¢‘åŸŸåˆ†æå’Œæ»¤æ³¢æ•ˆæœ
   - ğŸ’¾ è·å¾—å»å™ªå’Œå¢å¼ºåçš„éŸ³é¢‘

2. **ğŸ¼ éŸ³æºåˆ†ç¦»**

   - ğŸ“ é€‰æ‹©é¢„å¤„ç†åçš„éŸ³é¢‘ â†’ ç‚¹å‡»"ğŸµ å¼€å§‹åˆ†ç¦»"
   - â±ï¸ ç­‰å¾… Demucs æ¨¡å‹å¤„ç†ï¼ˆ3-10 åˆ†é’Ÿï¼‰
   - ğŸµ è·å¾—äººå£°ã€é¼“å£°ã€è´æ–¯ã€å…¶ä»–ä¹å™¨åˆ†ç¦»æ–‡ä»¶

3. **ğŸ‘¥ è¯´è¯äººåˆ†ç¦»**

   - ğŸ“ é€‰æ‹©äººå£°æ–‡ä»¶ â†’ ç‚¹å‡»"ğŸ‘¥ å¼€å§‹åˆ†ç¦»"
   - ğŸ¯ è‡ªåŠ¨è¯†åˆ«å’Œåˆ†ç¦»å¤šä¸ªè¯´è¯äºº
   - ğŸ“„ ç”Ÿæˆè¯´è¯äººæ—¶é—´è½´(RTTM)å’Œç‹¬ç«‹éŸ³é¢‘æ–‡ä»¶

4. **ğŸ” è¯­éŸ³åŒ¹é…**
   - ğŸµ é€‰æ‹©å‚è€ƒéŸ³é¢‘ï¼ˆç›®æ ‡è¯´è¯äººæ ·æœ¬ï¼‰
   - ğŸª é€‰æ‹©å¾…åŒ¹é…éŸ³é¢‘ï¼ˆå€™é€‰è¯´è¯äººæ–‡ä»¶ï¼‰
   - ğŸš€ ç‚¹å‡»"å¼€å§‹å¤„ç†" â†’ è·å¾—æœ€ä½³åŒ¹é…ç»“æœ

#### ğŸ¨ ç•Œé¢ç‰¹è‰²åŠŸèƒ½

- **ğŸ“Š å®æ—¶å¯è§†åŒ–**ï¼šæ³¢å½¢ã€é¢‘è°±ã€æ—¶é¢‘å›¾åŠ¨æ€æ˜¾ç¤º
- **ğŸ’¬ æ§åˆ¶å°é›†æˆ**ï¼šå®æ—¶å¤„ç†çŠ¶æ€å’Œè¯¦ç»†æ—¥å¿—
- **ğŸ“ˆ è¿›åº¦è¿½è¸ª**ï¼šæ¯ä¸ªæ­¥éª¤çš„è¯¦ç»†è¿›åº¦æŒ‡ç¤º
- **ğŸ“‚ ç»“æœç®¡ç†**ï¼šä¸€é”®æ‰“å¼€è¾“å‡ºæ–‡ä»¶å¤¹å’ŒæŸ¥çœ‹æŠ¥å‘Š
- **ğŸ›ï¸ å‚æ•°è°ƒèŠ‚**ï¼šå¯è°ƒèŠ‚æ»¤æ³¢å™¨é¢‘ç‡ã€å™ªå£°é˜ˆå€¼ç­‰å‚æ•°

### ğŸ’» ä½¿ç”¨å‘½ä»¤è¡Œ

#### å®Œæ•´å¤„ç†ç®¡é“

```bash
# è¿è¡Œå®Œæ•´çš„è¯­éŸ³å¤„ç†æµç¨‹
python voice_processing_pipeline.py input/mixed_audio.wav reference/target_speaker.wav

# å¸¦è‡ªå®šä¹‰å‚æ•°
python voice_processing_pipeline.py \
    --input input/mixed_audio.wav \
    --reference reference/target_speaker.wav \
    --output output/final_result \
    --enable-preprocessing \
    --speaker-method pyannote
```

#### ç‹¬ç«‹æ¨¡å—ä½¿ç”¨

```bash
# ğŸšï¸ ä»…éŸ³é¢‘é¢„å¤„ç†
python -m modules.preprocessing.audio_preprocessor input/audio.wav \
    --output output/preprocessing \
    --low-freq 80 --high-freq 8000

# ğŸ¼ ä»…éŸ³æºåˆ†ç¦»
python -m modules.source_separation.demucs_separator input/audio.wav \
    --output output/demucs \
    --model htdemucs --device cpu

# ğŸ‘¥ ä»…è¯´è¯äººåˆ†ç¦»
python -m modules.speaker_separation.speaker_separator input/vocals.wav \
    --output output/speakers \
    --hf-token your_token

# ğŸ” ä»…è¯­éŸ³åŒ¹é…
python -m modules.voice_matching.voice_matcher reference.wav \
    --candidates candidate1.wav candidate2.wav candidate3.wav \
    --output output/matching
```

#### ğŸ“Š æ‰¹å¤„ç†æ¨¡å¼

```bash
# æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡ä»¶
python scripts/batch_process.py \
    --input-dir input/ \
    --reference-dir reference/ \
    --output-dir output/ \
    --format wav

# ç›‘æ§æ–‡ä»¶å¤¹è‡ªåŠ¨å¤„ç†
python scripts/watch_folder.py \
    --watch-dir input/ \
    --reference-audio reference/target.wav \
    --output-dir output/
```

## ğŸ“š ä½¿ç”¨æ•™ç¨‹

### ğŸšï¸ 1. éŸ³é¢‘é¢„å¤„ç†

éŸ³é¢‘é¢„å¤„ç†æ¨¡å—åº”ç”¨ä¿¡å·å¤„ç†æŠ€æœ¯æå‡éŸ³é¢‘è´¨é‡ï¼š

```python
from modules.preprocessing import AudioPreprocessor

# åˆå§‹åŒ–é¢„å¤„ç†å™¨
preprocessor = AudioPreprocessor(sample_rate=16000)

# å¤„ç†éŸ³é¢‘æ–‡ä»¶
results = preprocessor.process_audio(
    input_path="input/mixed_audio.wav",
    output_dir="output/preprocessing",
    apply_bandpass=True,           # å¯ç”¨å¸¦é€šæ»¤æ³¢
    apply_spectral_subtraction=True, # å¯ç”¨è°±å‡æ³•é™å™ª
    low_freq=80,                   # ä½é¢‘æˆªæ­¢é¢‘ç‡
    high_freq=8000,               # é«˜é¢‘æˆªæ­¢é¢‘ç‡
    noise_reduction_alpha=2.0      # è°±å‡æ³•å‚æ•°
)

print(f"âœ… é¢„å¤„ç†å®Œæˆ: {results['output_path']}")
print(f"ğŸ“Š å¤„ç†æŠ¥å‘Š: {results['report_path']}")
```

**ğŸ”§ æŠ€æœ¯åŸç†**ï¼š

- **FFT åˆ†æ**ï¼šé¢‘åŸŸç‰¹å¾æå–å’Œå™ªå£°è¯†åˆ«
- **å·´ç‰¹æ²ƒæ–¯æ»¤æ³¢å™¨**ï¼šä¿ç•™è¯­éŸ³é¢‘æ®µ(80Hz-8kHz)
- **è°±å‡æ³•**ï¼šåŸºäºå™ªå£°è°±çš„èƒŒæ™¯å™ªå£°æŠ‘åˆ¶
- **ç»´çº³æ»¤æ³¢**ï¼šåŸºäºä¿¡å™ªæ¯”çš„æœ€ä¼˜æ»¤æ³¢

### ğŸ¼ 2. éŸ³æºåˆ†ç¦»

ä½¿ç”¨ Demucs æ¨¡å‹å°†æ··åˆéŸ³é¢‘åˆ†ç¦»ä¸ºä¸åŒçš„éŸ³è½¨ï¼š

```python
from modules.source_separation import DemucsSourceSeparator

# åˆå§‹åŒ–åˆ†ç¦»å™¨
separator = DemucsSourceSeparator(model_name="htdemucs")

# æ‰§è¡ŒéŸ³æºåˆ†ç¦»
results = separator.separate_audio(
    input_path="input/mixed_audio.wav",
    output_dir="output/demucs_output",
    device="cpu"  # æˆ– "cuda" å¯ç”¨GPUåŠ é€Ÿ
)

# è·å–åˆ†ç¦»åçš„æ–‡ä»¶
vocals_file = results['separated_files']['vocals']
drums_file = results['separated_files']['drums']
bass_file = results['separated_files']['bass']
other_file = results['separated_files']['other']

print(f"ğŸµ äººå£°æ–‡ä»¶: {vocals_file}")
print(f"ğŸ¥ é¼“å£°æ–‡ä»¶: {drums_file}")
```

**ğŸš€ æ€§èƒ½ä¼˜åŒ–**ï¼š

- **GPU åŠ é€Ÿ**ï¼šä½¿ç”¨ CUDA å¯æå‡ 3-5 å€å¤„ç†é€Ÿåº¦
- **æ¨¡å‹é€‰æ‹©**ï¼šhtdemucs åœ¨äººå£°åˆ†ç¦»ä¸Šæ•ˆæœæœ€ä½³
- **å†…å­˜ç®¡ç†**ï¼šå¤§æ–‡ä»¶è‡ªåŠ¨åˆ†å—å¤„ç†

### ğŸ‘¥ 3. è¯´è¯äººåˆ†ç¦»

è¯†åˆ«å’Œåˆ†ç¦»éŸ³é¢‘ä¸­çš„ä¸åŒè¯´è¯äººï¼š

```python
from modules.speaker_separation import SpeakerSeparator

# åˆå§‹åŒ–è¯´è¯äººåˆ†ç¦»å™¨ (éœ€è¦HF Token)
separator = SpeakerSeparator(hf_token="your_huggingface_token")

# æ‰§è¡Œè¯´è¯äººåˆ†ç¦»
results = separator.separate_speakers(
    input_path="path/to/vocals.wav",
    output_dir="output/speaker_output"
)

# æŸ¥çœ‹åˆ†ç¦»ç»“æœ
for speaker_id, file_path in results['separated_files'].items():
    print(f"ğŸ‘¤ è¯´è¯äºº {speaker_id}: {file_path}")

# æŸ¥çœ‹è¯´è¯äººæ—¶é—´è½´
rttm_file = results['diarization_file']
print(f"ğŸ“… æ—¶é—´è½´æ–‡ä»¶: {rttm_file}")
```

**ğŸ¯ å…³é”®ç‰¹æ€§**ï¼š

- **è‡ªåŠ¨æ£€æµ‹**ï¼šæ— éœ€é¢„çŸ¥è¯´è¯äººæ•°é‡
- **æ—¶é—´è½´æ ‡æ³¨**ï¼šç²¾ç¡®çš„è¯´è¯æ—¶é—´æ®µæ ‡è®°
- **é‡å å¤„ç†**ï¼šå¤„ç†è¯´è¯äººé‡å åŒºåŸŸ

### ğŸ” 4. è¯­éŸ³åŒ¹é…

åŸºäºå‚è€ƒéŸ³é¢‘æ‰¾åˆ°æœ€ç›¸ä¼¼çš„è¯­éŸ³ï¼š

```python
from modules.voice_matching import VoiceMatcher

# åˆå§‹åŒ–è¯­éŸ³åŒ¹é…å™¨
matcher = VoiceMatcher(sample_rate=16000)

# æ‰§è¡Œè¯­éŸ³åŒ¹é…
results = matcher.match_voices(
    reference_path="reference/target_voice.wav",
    candidate_paths=[
        "speakers/speaker1.wav",
        "speakers/speaker2.wav",
        "speakers/speaker3.wav"
    ],
    output_dir="output/final_output"
)

# æŸ¥çœ‹åŒ¹é…ç»“æœ
best_match = results['best_match_name']
similarity_score = results['best_score']
output_file = results['best_match_output']

print(f"ğŸ¯ æœ€ä½³åŒ¹é…: {best_match}")
print(f"ğŸ“Š ç›¸ä¼¼åº¦è¯„åˆ†: {similarity_score:.3f}")
print(f"ğŸµ è¾“å‡ºæ–‡ä»¶: {output_file}")
```

**ğŸ”¬ ç‰¹å¾åˆ†æ**ï¼š

- **MFCC ç‰¹å¾**ï¼š13 ç»´æ¢…å°”é¢‘ç‡å€’è°±ç³»æ•°
- **è°±ç‰¹å¾**ï¼šé¢‘è°±è´¨å¿ƒã€å¸¦å®½ã€å¯¹æ¯”åº¦
- **æ—¶åŸŸç‰¹å¾**ï¼šé›¶äº¤å‰ç‡ã€èƒ½é‡åˆ†å¸ƒ
- **ç›¸ä¼¼åº¦ç®—æ³•**ï¼šä½™å¼¦ç›¸ä¼¼åº¦ + çš®å°”é€Šç›¸å…³
  high_freq=8000
  )

````

### 2. Source Separation

Separate mixed audio into individual instrument/vocal stems:

```python
from modules.source_separation import DemucsSourceSeparator

separator = DemucsSourceSeparator(model_name="htdemucs")
results = separator.separate_audio(
    input_path="input/mixed_audio.wav",
    output_dir="output/demucs_output",
    device="cpu"  # or "cuda" for GPU acceleration
)

# Access separated vocals
vocals_file = results['separated_files']['vocals']
````

### 3. Speaker Separation

Identify and separate individual speakers:

```python
from modules.speaker_separation import SpeakerSeparator

separator = SpeakerSeparator(hf_token="your_hf_token")
results = separator.separate_speakers_pyannote(
    input_path="path/to/vocals.wav",
    output_dir="output/speaker_output"
)

# Access separated speakers
for speaker_id, file_path in results['separated_files'].items():
    print(f"Speaker {speaker_id}: {file_path}")
```

### 4. Voice Matching

Find the best matching voice against a reference:

```python
from modules.voice_matching import VoiceMatcher

matcher = VoiceMatcher(sample_rate=16000)
results = matcher.match_voices(
    reference_path="reference/target_voice.wav",
    candidate_paths=["speaker1.wav", "speaker2.wav", "speaker3.wav"],
    output_dir="output/final_output"
)

# Best match results
best_match = results['best_match_name']
similarity_score = results['best_score']
output_file = results['best_match_output']
```

## Technical Details

### Signal Processing Theory

The system implements several fundamental signal processing concepts:

1. **Fast Fourier Transform (FFT)**: For frequency domain analysis and filter design
2. **Butterworth Filters**: For optimal passband characteristics in voice frequency range
3. **Spectral Subtraction**: Classical noise reduction technique
4. **Mel-Frequency Cepstral Coefficients (MFCC)**: For voice feature extraction
5. **Short-Time Fourier Transform (STFT)**: For time-frequency analysis

### Machine Learning Components

- **Demucs**: Hybrid Transformer-based source separation model
- **Pyannote**: Speaker diarization using neural embeddings
- **VoiceFilter-WavLM**: Reference-based voice separation
- **Feature Extraction**: Multi-dimensional voice characteristic analysis

### Performance Optimization

- **Multi-threading**: Background processing with progress updates
- **Memory Management**: Efficient audio buffer handling
- **Model Caching**: Automatic model download and storage
- **GPU Acceleration**: Optional CUDA support for faster processing

## File Formats

### Supported Input Formats

- WAV (recommended for best quality)
- MP3, FLAC, OGG, M4A

### Output Formats

- WAV (16-bit PCM for compatibility)
- Comprehensive analysis reports (TXT)
- Visualization plots (PNG)

## Troubleshooting

### Common Issues

**Q: "Demucs model download fails"**
A: Ensure stable internet connection and sufficient disk space

**Q: "Hugging Face authentication error"**
A: Verify your HF token in the speaker separation module

**Q: "GPU out of memory"**
A: Switch to CPU processing by setting `device="cpu"`

**Q: "Audio file not recognized"**
A: Ensure file is in supported format. Try converting to WAV format first.

## License

This project is licensed under the MIT License - see the LICENSE file for details.

---

**Contact**: For questions or issues, please open an issue on GitHub.
**Version**: 1.0.0python
def separate_sources_with_demucs(self, input_audio_path):
"""ä½¿ç”¨ Demucs è¿›è¡ŒéŸ³æºåˆ†ç¦»""" # æ¨¡å‹é€‰æ‹©ï¼šhtdemucs ä¸ºäººå£°åˆ†ç¦»ä¼˜åŒ–
model_name = "htdemucs"
output_dir = self.temp_dir / "separated"

    # æ‰§è¡Œåˆ†ç¦»å‘½ä»¤
    command = [
        "python", "-m", "demucs.separate",
        "--mp3", "--two-stems=vocals",
        "-n", model_name, "-o", str(output_dir),
        str(input_audio_path)
    ]

````

**æŠ€æœ¯ç‰¹ç‚¹**:

- ç«¯åˆ°ç«¯æ·±åº¦å­¦ä¹ æ¶æ„
- æ”¯æŒå®æ—¶å’Œæ‰¹å¤„ç†æ¨¡å¼
- å¤šç§é¢„è®­ç»ƒæ¨¡å‹é€‰æ‹©
- é«˜è´¨é‡éŸ³é¢‘é‡å»º

### 2. è¯´è¯äººè¯†åˆ«ç®—æ³•

åŸºäº MFCCï¼ˆæ¢…å°”é¢‘ç‡å€’è°±ç³»æ•°ï¼‰çš„è¯´è¯äººç‰¹å¾åŒ¹é…ï¼š

```python
def extract_mfcc_features(self, audio_signal):
    """æå–MFCCç‰¹å¾ç”¨äºè¯´è¯äººè¯†åˆ«"""
    # è®¡ç®—MFCCç‰¹å¾
    mfcc = librosa.feature.mfcc(
        y=audio_signal,
        sr=self.sample_rate,
        n_mfcc=13,           # 13ç»´MFCCç³»æ•°
        n_fft=2048,          # FFTçª—å£å¤§å°
        hop_length=512,      # è·³è·ƒé•¿åº¦
        n_mels=128           # æ¢…å°”æ»¤æ³¢å™¨æ•°é‡
    )

    # è®¡ç®—ä¸€é˜¶å’ŒäºŒé˜¶å·®åˆ†
    delta_mfcc = librosa.feature.delta(mfcc)
    delta2_mfcc = librosa.feature.delta(mfcc, order=2)

    # ç»„åˆç‰¹å¾å‘é‡
    features = np.concatenate([mfcc, delta_mfcc, delta2_mfcc])
    return features
````

**ç®—æ³•ä¼˜åŠ¿**:

- å¯¹å™ªå£°å…·æœ‰è‰¯å¥½çš„é²æ£’æ€§
- è®¡ç®—æ•ˆç‡é«˜ï¼Œé€‚åˆå®æ—¶å¤„ç†
- ç‰¹å¾ç»´åº¦å¯è°ƒï¼Œå¹³è¡¡ç²¾åº¦ä¸é€Ÿåº¦
- æ”¯æŒçŸ­æ—¶å’Œé•¿æ—¶è¯´è¯äººå»ºæ¨¡

### 3. LTI æ»¤æ³¢å™¨è®¾è®¡

å®ç°å·´ç‰¹æ²ƒæ–¯å¸¦é€šæ»¤æ³¢å™¨ç”¨äºè¯­éŸ³å¢å¼ºï¼š

```python
def design_butterworth_filter(self, low_cutoff, high_cutoff, order=5):
    """è®¾è®¡å·´ç‰¹æ²ƒæ–¯å¸¦é€šæ»¤æ³¢å™¨"""
    nyquist = self.sample_rate / 2
    low_norm = low_cutoff / nyquist
    high_norm = high_cutoff / nyquist

    # è®¾è®¡å¸¦é€šæ»¤æ³¢å™¨
    b, a = signal.butter(
        order,
        [low_norm, high_norm],
        btype='band',
        analog=False
    )

    return b, a
```

**è®¾è®¡ç‰¹ç‚¹**:

- å¹³å¦çš„é€šå¸¦å“åº”
- å¯è°ƒèŠ‚çš„æˆªæ­¢é¢‘ç‡
- é›¶ç›¸ä½æ»¤æ³¢é€‰é¡¹
- å®æ—¶æ»¤æ³¢å™¨ç³»æ•°æ›´æ–°

## æŠ€æœ¯æ¶æ„

### ç³»ç»Ÿæ¨¡å—ç»“æ„

```
voice_processing/
â”œâ”€â”€ main.py                 # ç¨‹åºå…¥å£ç‚¹
â”œâ”€â”€ requirements.txt        # ä¾èµ–åŒ…é…ç½®
â”œâ”€â”€ setup.py               # å®‰è£…é…ç½®
â”‚
â”œâ”€â”€ gui/                   # ç”¨æˆ·ç•Œé¢å±‚
â”‚   â”œâ”€â”€ ui_main.py        # UIå¸ƒå±€å®šä¹‰
â”‚   â”œâ”€â”€ app.py            # ä¸»åº”ç”¨é€»è¾‘
â”‚   â””â”€â”€ app_fixed.py      # ä¿®å¤ç‰ˆæœ¬
â”‚
â”œâ”€â”€ core/                  # æ ¸å¿ƒå¤„ç†å±‚
â”‚   â”œâ”€â”€ process_pipeline.py  # ä¸»å¤„ç†æµç¨‹
â”‚   â”œâ”€â”€ filters.py           # æ»¤æ³¢å™¨å®ç°
â”‚   â”œâ”€â”€ match_speaker.py     # è¯´è¯äººåŒ¹é…
â”‚   â””â”€â”€ analyze.py           # éŸ³é¢‘åˆ†æ
â”‚
â”œâ”€â”€ input/                 # è¾“å…¥éŸ³é¢‘ç›®å½•
â”œâ”€â”€ reference/             # å‚è€ƒéŸ³é¢‘ç›®å½•
â”œâ”€â”€ output/                # å¤„ç†ç»“æœç›®å½•
â””â”€â”€ temp/                  # ä¸´æ—¶æ–‡ä»¶ç›®å½•
```

### æ•°æ®æµæ¶æ„

```mermaid
graph TD
    A[è¾“å…¥éŸ³é¢‘] --> B[éŸ³æºåˆ†ç¦»]
    C[å‚è€ƒéŸ³é¢‘] --> D[ç‰¹å¾æå–]
    B --> E[äººå£°æå–]
    E --> F[è¯´è¯äººåŒ¹é…]
    D --> F
    F --> G[å¸¦é€šæ»¤æ³¢]
    G --> H[åå¤„ç†å¢å¼º]
    H --> I[è¾“å‡ºéŸ³é¢‘]

    J[å®æ—¶å¯è§†åŒ–] --> K[æ³¢å½¢æ˜¾ç¤º]
    J --> L[é¢‘è°±åˆ†æ]
    J --> M[æ»¤æ³¢å™¨å“åº”]
    J --> N[æ—¶é¢‘å›¾]
```

### å…³é”®ç±»è®¾è®¡

#### ProcessPipeline - ä¸»å¤„ç†ç®¡é“

```python
class ProcessPipeline:
    """éŸ³é¢‘å¤„ç†ä¸»æµç¨‹ç®¡é“"""

    def __init__(self, sample_rate=22050):
        self.sample_rate = sample_rate
        self.voice_filter = VoiceEnhancementFilter(sample_rate)
        self.speaker_matcher = SpeakerMatcher(sample_rate)
        self.analyzer = AudioAnalyzer(sample_rate)

    def process_audio(self, input_path, reference_path, low_freq=300, high_freq=3400):
        """å®Œæ•´çš„éŸ³é¢‘å¤„ç†æµç¨‹"""
        # 1. éŸ³æºåˆ†ç¦»
        separated_files = self.separate_sources_with_demucs(input_path)

        # 2. è¯´è¯äººåŒ¹é…
        matched_audio, confidence = self.match_target_speaker(
            reference_path, separated_files['vocals']
        )

        # 3. è¯­éŸ³å¢å¼º
        enhanced_audio = self.apply_voice_enhancement(
            matched_audio, low_freq, high_freq
        )

        # 4. åå¤„ç†
        final_audio = self.post_process_audio(enhanced_audio)

        return final_audio
```

#### VoiceEnhancementFilter - è¯­éŸ³å¢å¼ºæ»¤æ³¢å™¨

```python
class VoiceEnhancementFilter(BandpassFilter):
    """äººå£°å¢å¼ºæ»¤æ³¢å™¨ç±»"""

    def apply_voice_enhancement(self, audio_signal, low_cutoff=300,
                               high_cutoff=3400, pre_emphasis=True,
                               post_processing=True):
        """å®Œæ•´çš„äººå£°å¢å¼ºå¤„ç†æµç¨‹"""
        enhanced_signal = audio_signal.copy()

        # é¢„åŠ é‡å¤„ç†
        if pre_emphasis:
            enhanced_signal = self.apply_pre_emphasis(enhanced_signal)

        # å¸¦é€šæ»¤æ³¢
        b, a = self.design_butterworth_filter(low_cutoff, high_cutoff)
        enhanced_signal = self.apply_filter(enhanced_signal, b, a)

        # åå¤„ç†ä¼˜åŒ–
        if post_processing:
            enhanced_signal = self.apply_post_processing(enhanced_signal)

        return enhanced_signal
```

## ä¿¡å·å¤„ç†ç†è®º

â”‚ â”œâ”€â”€ process_pipeline.py # ä¸»å¤„ç†æµç¨‹
â”‚ â”œâ”€â”€ filters.py # æ»¤æ³¢å™¨è®¾è®¡
â”‚ â”œâ”€â”€ match_speaker.py # è¯´è¯äººåŒ¹é…
â”‚ â””â”€â”€ analyze.py # éŸ³é¢‘åˆ†æ
â”œâ”€â”€ input/ # è¾“å…¥éŸ³é¢‘ç›®å½•
â”œâ”€â”€ reference/ # å‚è€ƒéŸ³é¢‘ç›®å½•
â”œâ”€â”€ output/ # å¤„ç†ç»“æœç›®å½•
â””â”€â”€ main.py # ç¨‹åºå…¥å£

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- Python 3.10+
- æ¨èä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ

### å®‰è£…æ­¥éª¤

1. **å…‹éš†é¡¹ç›®**

```bash
git clone [é¡¹ç›®åœ°å€]
cd voice_processing
```

2. **å®‰è£…ä¾èµ–**

```bash
pip install -r requirements.txt
```

3. **è¿è¡Œç¨‹åº**

```bash
python main.py
```

### ä¾èµ–åŒ…è¯´æ˜

| åŒ…å       | ç‰ˆæœ¬    | ç”¨é€”               |
| ---------- | ------- | ------------------ |
| PyQt6      | â‰¥6.5.0  | ç°ä»£åŒ– GUI æ¡†æ¶    |
| librosa    | â‰¥0.10.0 | éŸ³é¢‘å¤„ç†å’Œç‰¹å¾æå– |
| demucs     | â‰¥4.0.0  | éŸ³æºåˆ†ç¦»           |
| matplotlib | â‰¥3.7.0  | æ•°æ®å¯è§†åŒ–         |
| numpy      | â‰¥1.24.0 | æ•°å€¼è®¡ç®—           |
| scipy      | â‰¥1.10.0 | ç§‘å­¦è®¡ç®—           |

## ğŸ’» ä½¿ç”¨æŒ‡å—

### åŸºæœ¬æ“ä½œæµç¨‹

1. **é€‰æ‹©æ··åˆéŸ³é¢‘æ–‡ä»¶**

   - ç‚¹å‡»"ğŸµ é€‰æ‹©æ··åˆéŸ³é¢‘æ–‡ä»¶"
   - æ”¯æŒ WAVã€MP3ã€FLACã€M4A æ ¼å¼

2. **é€‰æ‹©å‚è€ƒä¸»äººå£°éŸ³é¢‘**

   - ç‚¹å‡»"ğŸ¤ é€‰æ‹©å‚è€ƒä¸»äººå£°éŸ³é¢‘"
   - æä¾›ç›®æ ‡è¯´è¯äººçš„éŸ³é¢‘æ ·æœ¬

3. **è°ƒæ•´æ»¤æ³¢å™¨å‚æ•°**

   - ä½é¢‘æˆªæ­¢ï¼š20-2000 Hz (é»˜è®¤ 300 Hz)
   - é«˜é¢‘æˆªæ­¢ï¼š2000-8000 Hz (é»˜è®¤ 3400 Hz)
   - å®æ—¶æ˜¾ç¤ºé¢‘ç‡å“åº”æ›²çº¿

4. **å¼€å§‹å¤„ç†**

   - ç‚¹å‡»"ğŸš€ å¼€å§‹ä¸»äººå£°æå–"
   - è§‚å¯Ÿå¤„ç†è¿›åº¦å’ŒçŠ¶æ€æç¤º

5. **æŸ¥çœ‹ç»“æœ**
   - è‡ªåŠ¨æ˜¾ç¤ºå¤„ç†å‰åå¯¹æ¯”å›¾
   - æ”¯æŒæ³¢å½¢å›¾å’Œé¢‘è°±å›¾åˆ‡æ¢

### ç•Œé¢åŠŸèƒ½è¯´æ˜

#### ğŸ“ æ–‡ä»¶é€‰æ‹©åŒºåŸŸ

- æ··åˆéŸ³é¢‘æ–‡ä»¶é€‰æ‹©
- å‚è€ƒéŸ³é¢‘æ–‡ä»¶é€‰æ‹©
- æ–‡ä»¶è·¯å¾„æ˜¾ç¤º

#### âš™ï¸ å‚æ•°è®¾ç½®åŒºåŸŸ

- ä½é¢‘æˆªæ­¢é¢‘ç‡æ»‘å—
- é«˜é¢‘æˆªæ­¢é¢‘ç‡æ»‘å—
- å®æ—¶æ•°å€¼æ˜¾ç¤º

#### ğŸ¯ æ§åˆ¶æ“ä½œåŒºåŸŸ

- ä¸»å¤„ç†æŒ‰é’®
- è¿›åº¦æ¡æ˜¾ç¤º
- éŸ³é¢‘æ’­æ”¾æ§åˆ¶

#### ğŸ“Š å¯è§†åŒ–åŒºåŸŸ

- æ—¶åŸŸæ³¢å½¢å›¾
- é¢‘åŸŸé¢‘è°±å›¾
- æ»¤æ³¢å™¨å“åº”å›¾

## ğŸ”¬ æŠ€æœ¯ç»†èŠ‚

### éŸ³æºåˆ†ç¦»æŠ€æœ¯

ä½¿ç”¨ **Demucs** æ·±åº¦å­¦ä¹ æ¨¡å‹è¿›è¡ŒéŸ³æºåˆ†ç¦»ï¼š

- åŸºäº U-Net æ¶æ„çš„ç«¯åˆ°ç«¯å­¦ä¹ 
- èƒ½å¤Ÿåˆ†ç¦»äººå£°ã€é¼“å£°ã€è´æ–¯ã€å…¶ä»–ä¹å™¨
- å¤‡ç”¨æ–¹æ¡ˆï¼šåŸºäºç«‹ä½“å£° Mid-Side å¤„ç†

### è¯´è¯äººè¯†åˆ«ç®—æ³•

é‡‡ç”¨å¤šç‰¹å¾èåˆçš„åŒ¹é…ç®—æ³•ï¼š

1. **MFCC ç‰¹å¾** (Mel-frequency Cepstral Coefficients)

   - æ¨¡æ‹Ÿäººè€³å¬è§‰ç‰¹æ€§
   - 13 ç»´ç³»æ•° + ä¸€é˜¶äºŒé˜¶å·®åˆ†
   - æ€»å…± 39 ç»´ç‰¹å¾å‘é‡

2. **é¢‘è°±ç‰¹å¾**

   - å…‰è°±è´¨å¿ƒ (éŸ³è‰²äº®åº¦)
   - å…‰è°±å¸¦å®½ (éŸ³è‰²ä¸°å¯Œåº¦)
   - å…‰è°±å¯¹æ¯”åº¦
   - é›¶äº¤å‰ç‡

3. **åŸºé¢‘ç‰¹å¾**
   - YIN ç®—æ³•æå– F0
   - ç»Ÿè®¡ç‰¹å¾ (å‡å€¼ã€æ–¹å·®ã€èŒƒå›´)

### æ»¤æ³¢å™¨è®¾è®¡

#### å·´ç‰¹æ²ƒæ–¯å¸¦é€šæ»¤æ³¢å™¨

```python
# è®¾è®¡å…¬å¼
H(s) = K / (1 + (s/Ï‰c)^(2n))

# æ•°å­—å®ç°
b, a = butter(order, [low_norm, high_norm], btype='band')
```

#### å…³é”®å‚æ•°

- **é€šå¸¦èŒƒå›´**ï¼š300-3400 Hz (è¯­éŸ³æ¸…æ™°åº¦æœ€ä½³é¢‘æ®µ)
- **æ»¤æ³¢å™¨é˜¶æ•°**ï¼š5 é˜¶ (å¹³è¡¡é™¡å³­åº¦å’Œè®¡ç®—å¤æ‚åº¦)
- **å®ç°æ–¹æ³•**ï¼šé›¶ç›¸ä½æ»¤æ³¢ (filtfilt)

### åå¤„ç†ä¼˜åŒ–

1. **åŠ¨æ€èŒƒå›´å‹ç¼©**

   - å‹ç¼©æ¯”ï¼š4:1
   - é˜ˆå€¼ï¼š-20 dB

2. **å™ªå£°é—¨é™**

   - é—¨é™å€¼ï¼š-40 dB
   - è¡°å‡ç³»æ•°ï¼š0.1

3. **å½’ä¸€åŒ–**
   - å³°å€¼é™åˆ¶ï¼š0.95
   - é˜²æ­¢å‰Šæ³¢å¤±çœŸ

## ğŸ“Š æ€§èƒ½è¯„ä¼°

### è¯„ä¼°æŒ‡æ ‡

1. **ä¸»è§‚è¯„ä¼°**

   - è¯­éŸ³æ¸…æ™°åº¦
   - éŸ³è´¨è‡ªç„¶åº¦
   - èƒŒæ™¯å™ªå£°æŠ‘åˆ¶

2. **å®¢è§‚æŒ‡æ ‡**
   - ä¿¡å™ªæ¯” (SNR)
   - é¢‘è°±å¤±çœŸåº¦
   - åŒ¹é…ç½®ä¿¡åº¦

### å¤„ç†æ•ˆæœæŠ¥å‘Š

ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆè¯¦ç»†çš„å¤„ç†æŠ¥å‘Šï¼š

- åŒ¹é…ç½®ä¿¡åº¦åˆ†æ
- é¢‘è°±ç‰¹æ€§å˜åŒ–
- èƒ½é‡åˆ†å¸ƒå¯¹æ¯”
- å¤„ç†å‚æ•°è®°å½•

## ğŸ¨ ç•Œé¢è®¾è®¡

### è®¾è®¡ç†å¿µ

å‚è€ƒç°ä»£éŸ³ä¹æ’­æ”¾å™¨ (Spotifyã€Apple Music) çš„è®¾è®¡é£æ ¼ï¼š

- **æ·±è‰²ä¸»é¢˜**ï¼šå‡å°‘è§†è§‰ç–²åŠ³
- **åœ†è§’è®¾è®¡**ï¼šç°ä»£ç®€æ´ç¾è§‚
- **æ¸å˜è‰²å½©**ï¼šçªå‡ºé‡è¦æ“ä½œ
- **å“åº”å¼å¸ƒå±€**ï¼šé€‚é…ä¸åŒå±å¹•å°ºå¯¸

### é¢œè‰²æ–¹æ¡ˆ

- ä¸»èƒŒæ™¯ï¼š`#1e1e1e`
- æ¬¡è¦èƒŒæ™¯ï¼š`#2d2d2d`
- å¼ºè°ƒè‰²ï¼š`#4CAF50` (ç»¿è‰²)
- è­¦å‘Šè‰²ï¼š`#FF9800` (æ©™è‰²)
- é”™è¯¯è‰²ï¼š`#F44336` (çº¢è‰²)

## ğŸš§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **Demucs å®‰è£…å¤±è´¥**

```bash
# ä½¿ç”¨condaå®‰è£…
conda install pytorch torchaudio -c pytorch
pip install demucs
```

2. **éŸ³é¢‘æ–‡ä»¶åŠ è½½å¤±è´¥**

- æ£€æŸ¥æ–‡ä»¶æ ¼å¼æ˜¯å¦æ”¯æŒ
- ç¡®è®¤æ–‡ä»¶æ²¡æœ‰æŸå
- å°è¯•è½¬æ¢ä¸º WAV æ ¼å¼

3. **å¤„ç†é€Ÿåº¦è¿‡æ…¢**

- ä½¿ç”¨ GPU åŠ é€Ÿ (å¦‚æœå¯ç”¨)
- é™ä½éŸ³é¢‘é‡‡æ ·ç‡
- å‡å°‘éŸ³é¢‘æ–‡ä»¶é•¿åº¦

4. **åŒ¹é…ç½®ä¿¡åº¦è¿‡ä½**

- æä¾›æ›´æ¸…æ™°çš„å‚è€ƒéŸ³é¢‘
- ç¡®ä¿å‚è€ƒéŸ³é¢‘ä¸ç›®æ ‡ä¸€è‡´
- è°ƒæ•´æ»¤æ³¢å™¨å‚æ•°

### æ€§èƒ½ä¼˜åŒ–

1. **å†…å­˜ä½¿ç”¨**

   - åˆ†æ®µå¤„ç†é•¿éŸ³é¢‘
   - åŠæ—¶é‡Šæ”¾ä¸­é—´å˜é‡
   - ä½¿ç”¨ç”Ÿæˆå™¨é¿å…å…¨é‡åŠ è½½

2. **è®¡ç®—åŠ é€Ÿ**
   - NumPy å‘é‡åŒ–æ“ä½œ
   - å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†
   - GPU åŠ é€Ÿ (CUDA)

## ğŸ”® æœªæ¥æ”¹è¿›

### åŠŸèƒ½æ‰©å±•

- [ ] å®æ—¶éŸ³é¢‘å¤„ç†
- [ ] å¤šè¯´è¯äººåŒæ—¶åˆ†ç¦»
- [ ] å£°çº¹è¯†åˆ«é›†æˆ
- [ ] äº‘ç«¯å¤„ç†æ”¯æŒ

### ç®—æ³•ä¼˜åŒ–

- [ ] æ·±åº¦å­¦ä¹ è¯´è¯äººè¯†åˆ«
- [ ] è‡ªé€‚åº”æ»¤æ³¢å™¨
- [ ] å™ªå£°é²æ£’æ€§æå‡
- [ ] ç«¯åˆ°ç«¯ç¥ç»ç½‘ç»œ

### ç”¨æˆ·ä½“éªŒ

- [ ] éŸ³é¢‘æ’­æ”¾å™¨é›†æˆ
- [ ] æ‰¹é‡å¤„ç†æ¨¡å¼
- [ ] é¢„è®¾å‚æ•°æ¨¡æ¿
- [ ] å¤„ç†å†å²è®°å½•

## ğŸ“š å‚è€ƒèµ„æ–™

### å­¦æœ¯è®ºæ–‡

1. DÃ©fossez, A., et al. "Music source separation in the waveform domain." arXiv preprint (2019)
2. Davis, S., Mermelstein, P. "Comparison of parametric representations for monosyllabic word recognition." IEEE TASSP (1980)

### æŠ€æœ¯æ–‡æ¡£

- [librosa Documentation](https://librosa.org/)
- [PyQt6 Documentation](https://doc.qt.io/qtforpython/)
- [Demucs GitHub](https://github.com/facebook/demucs)

### è¯¾ç¨‹ç›¸å…³

- ä¿¡å·ä¸ç³»ç»Ÿç†è®ºåŸºç¡€
- æ•°å­—ä¿¡å·å¤„ç†æ–¹æ³•
- è¯­éŸ³ä¿¡å·å¤„ç†æŠ€æœ¯

## ğŸ‘¥ è´¡çŒ®æŒ‡å—

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

## ğŸ¤ è´¡çŒ®æŒ‡å—

### ğŸ’¡ å¦‚ä½•è´¡çŒ®

æˆ‘ä»¬æ¬¢è¿æ‰€æœ‰å½¢å¼çš„è´¡çŒ®ï¼š

1. **ğŸ“ é—®é¢˜æŠ¥å‘Š**ï¼šå‘ç° bug æˆ–æœ‰æ”¹è¿›å»ºè®®
2. **ğŸ”§ ä»£ç è´¡çŒ®**ï¼šæäº¤æ–°åŠŸèƒ½æˆ–ä¿®å¤
3. **ğŸ“š æ–‡æ¡£æ”¹è¿›**ï¼šå®Œå–„æ–‡æ¡£å’Œä½¿ç”¨ç¤ºä¾‹
4. **ğŸ§ª æµ‹è¯•ç”¨ä¾‹**ï¼šå¢åŠ æµ‹è¯•è¦†ç›–ç‡

### ğŸ› ï¸ å¼€å‘ç¯å¢ƒæ­å»º

```bash
# 1. Fork é¡¹ç›®å¹¶å…‹éš†
git clone https://github.com/your-username/voice_processing.git
cd voice_processing

# 2. åˆ›å»ºå¼€å‘ç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# 3. å®‰è£…å¼€å‘ä¾èµ–
pip install -r requirements.txt
pip install -r requirements-dev.txt

# 4. å®‰è£…é¢„æäº¤é’©å­
pre-commit install

# 5. è¿è¡Œæµ‹è¯•ç¡®è®¤ç¯å¢ƒæ­£å¸¸
python -m pytest tests/
```

### ğŸ“‹ ä»£ç è§„èŒƒ

- **PEP 8**ï¼šéµå¾ª Python å®˜æ–¹ç¼–ç è§„èŒƒ
- **ç±»å‹æç¤º**ï¼šä½¿ç”¨ typing æ¨¡å—æ·»åŠ ç±»å‹æ³¨è§£
- **æ–‡æ¡£å­—ç¬¦ä¸²**ï¼šæ‰€æœ‰å‡½æ•°å’Œç±»å¿…é¡»æœ‰è¯¦ç»†çš„ docstring
- **å•å…ƒæµ‹è¯•**ï¼šæ–°åŠŸèƒ½éœ€è¦é…å¥—çš„æµ‹è¯•ç”¨ä¾‹
- **ä»£ç å®¡æŸ¥**ï¼šæ‰€æœ‰ PR éœ€è¦ç»è¿‡ä»£ç å®¡æŸ¥

### ğŸ§ª æµ‹è¯•æŒ‡å—

```bash
# è¿è¡Œæ‰€æœ‰æµ‹è¯•
python -m pytest

# è¿è¡Œç‰¹å®šæ¨¡å—æµ‹è¯•
python -m pytest tests/test_preprocessing.py

# ç”Ÿæˆæµ‹è¯•è¦†ç›–ç‡æŠ¥å‘Š
python -m pytest --cov=modules tests/

# è¿è¡Œæ€§èƒ½æµ‹è¯•
python -m pytest tests/performance/
```

## ï¿½ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ **MIT è®¸å¯è¯** å¼€æº - è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶

```
MIT License

Copyright (c) 2025 Voice Processing Suite Team

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.
```

## ğŸ† è‡´è°¢

### ğŸ™ æŠ€æœ¯æ”¯æŒ

- **[Demucs](https://github.com/facebookresearch/demucs)** - éŸ³æºåˆ†ç¦»æ ¸å¿ƒç®—æ³•
- **[Pyannote](https://github.com/pyannote/pyannote-audio)** - è¯´è¯äººåˆ†ç¦»æŠ€æœ¯
- **[Librosa](https://librosa.org/)** - éŸ³é¢‘å¤„ç†åº“
- **[PyQt6](https://www.riverbankcomputing.com/software/pyqt/)** - GUI æ¡†æ¶

### ï¿½ å­¦æœ¯å‚è€ƒ

- DÃ©fossez, A., et al. "Music source separation in the waveform domain." (2019)
- Bredin, H., et al. "Pyannote.audio: Neural building blocks for speaker diarization." (2020)
- Davis, S., Mermelstein, P. "Comparison of parametric representations for monosyllabic word recognition." (1980)

### ğŸ“ è¯¾ç¨‹æ”¯æŒ

æ„Ÿè°¢**ä¿¡å·ä¸ç³»ç»Ÿ**è¯¾ç¨‹ç»„æä¾›çš„ç†è®ºåŸºç¡€å’Œå®è·µæŒ‡å¯¼ã€‚

## ï¿½ğŸ“ è”ç³»æ–¹å¼

### ğŸ‘¥ é¡¹ç›®å›¢é˜Ÿ

- **é¡¹ç›®è´Ÿè´£äºº**ï¼šä¿¡å·ä¸ç³»ç»Ÿè¯¾ç¨‹ç»„
- **å¼€å‘å›¢é˜Ÿ**ï¼šè¯¾ç¨‹å­¦ä¹ å°ç»„
- **æŠ€æœ¯æŒ‡å¯¼**ï¼šè¯¾ç¨‹æ•™å¸ˆå›¢é˜Ÿ

### ğŸ“§ æ”¯æŒæ¸ é“

- **ğŸ› é—®é¢˜æŠ¥å‘Š**ï¼š[GitHub Issues](https://github.com/your-repo/voice_processing/issues)
- **ğŸ’¬ è®¨è®ºäº¤æµ**ï¼š[GitHub Discussions](https://github.com/your-repo/voice_processing/discussions)
- **ğŸ“– æ–‡æ¡£æ›´æ–°**ï¼š[Wiki](https://github.com/your-repo/voice_processing/wiki)
- **ğŸ“§ é‚®ä»¶è”ç³»**ï¼švoice.processing@example.com

### ğŸŒŸ é¡¹ç›®çŠ¶æ€

![GitHub stars](https://img.shields.io/github/stars/your-repo/voice_processing)
![GitHub forks](https://img.shields.io/github/forks/your-repo/voice_processing)
![GitHub issues](https://img.shields.io/github/issues/your-repo/voice_processing)
![GitHub license](https://img.shields.io/github/license/your-repo/voice_processing)

---

<div align="center">

## ğŸ¯ é¡¹ç›®æ„¿æ™¯

**å°†ä¿¡å·ä¸ç³»ç»Ÿç†è®ºè½¬åŒ–ä¸ºå®é™…å¯ç”¨çš„è¯­éŸ³å¤„ç†å·¥å…·**

é€šè¿‡æœ¬é¡¹ç›®ï¼Œæˆ‘ä»¬å¸Œæœ›ï¼š

- ğŸ“ **æ•™è‚²ä»·å€¼**ï¼šä¸ºä¿¡å·å¤„ç†è¯¾ç¨‹æä¾›ç›´è§‚çš„å®è·µå¹³å°
- ğŸ”§ **å®ç”¨å·¥å…·**ï¼šè§£å†³å®é™…çš„è¯­éŸ³å¤„ç†éœ€æ±‚
- ğŸŒŸ **æŠ€æœ¯åˆ›æ–°**ï¼šæ¢ç´¢ä¼ ç»Ÿç†è®ºä¸ç°ä»£ AI çš„ç»“åˆ
- ğŸ¤ **çŸ¥è¯†åˆ†äº«**ï¼šå»ºç«‹å¼€æºçš„è¯­éŸ³å¤„ç†ç¤¾åŒº

### ğŸ“ˆ é¡¹ç›®ç»Ÿè®¡

| æŒ‡æ ‡          | æ•°å€¼         |
| ------------- | ------------ |
| ğŸ—‚ï¸ ä»£ç è¡Œæ•°   | 10,000+      |
| ğŸ§ª æµ‹è¯•è¦†ç›–ç‡ | 85%+         |
| ğŸ“Š å¤„ç†å‡†ç¡®ç‡ | 90%+         |
| âš¡ å¤„ç†é€Ÿåº¦   | 0.3x å®æ—¶    |
| ğŸ¯ æ”¯æŒæ ¼å¼   | 5 ç§éŸ³é¢‘æ ¼å¼ |
| ğŸŒ æ”¯æŒè¯­è¨€   | ä¸­è‹±åŒè¯­     |

**ğŸš€ ç«‹å³å¼€å§‹ä½ çš„è¯­éŸ³å¤„ç†ä¹‹æ—…ï¼**

[â¬‡ï¸ ä¸‹è½½é¡¹ç›®](https://github.com/your-repo/voice_processing/releases) |
[ğŸ“– æŸ¥çœ‹æ–‡æ¡£](https://github.com/your-repo/voice_processing/wiki) |
[ğŸ’¬ åŠ å…¥è®¨è®º](https://github.com/your-repo/voice_processing/discussions)

</div>

---

> **ğŸ“ è¿™æ˜¯ä¸€ä¸ªä¿¡å·ä¸ç³»ç»Ÿè¯¾ç¨‹çš„æœŸæœ«é¡¹ç›®ï¼Œæ—¨åœ¨é€šè¿‡å®é™…åº”ç”¨åŠ æ·±å¯¹ç†è®ºçŸ¥è¯†çš„ç†è§£ï¼ŒåŒæ—¶ä¸ºè¯­éŸ³å¤„ç†é¢†åŸŸè´¡çŒ®å¼€æºå·¥å…·ã€‚**
