#!/usr/bin/env python3
"""
ç®€åŒ–ç‰ˆäººå£°åŒ¹é…å™¨ - åŸºäºå‚è€ƒéŸ³é¢‘é€‰æ‹©æœ€åŒ¹é…çš„åˆ†ç¦»äººå£°
Simplified Voice Matcher - Select the best matching separated voice based on reference audio
"""

import numpy as np
import librosa
import soundfile as sf
from pathlib import Path
import matplotlib.pyplot as plt
from scipy.spatial.distance import cosine
from scipy.stats import pearsonr
import shutil

class SimpleVoiceMatcher:
    """ç®€åŒ–ç‰ˆäººå£°åŒ¹é…å™¨"""
    
    def __init__(self, sample_rate=16000):
        self.sample_rate = sample_rate
        self.hop_length = 512
        self.n_fft = 2048
        self.n_mfcc = 13
        
    def load_audio(self, audio_path):
        """åŠ è½½éŸ³é¢‘æ–‡ä»¶"""
        try:
            audio, sr = librosa.load(audio_path, sr=self.sample_rate)
            print(f"  åŠ è½½: {Path(audio_path).name} ({len(audio)/self.sample_rate:.1f}s)")
            return audio
        except Exception as e:
            print(f"  âŒ åŠ è½½å¤±è´¥ {audio_path}: {e}")
            return None
    
    def convert_audio_format(self, input_path, output_path):
        """è½¬æ¢éŸ³é¢‘æ ¼å¼ï¼ˆ64ä½è½¬16ä½ï¼‰"""
        try:
            data, samplerate = sf.read(input_path)
            
            # å½’ä¸€åŒ–å¤„ç†
            max_val = np.max(np.abs(data))
            if max_val > 1:
                data = data / max_val
            
            data = np.clip(data, -1.0, 1.0) * 0.98
            data_int16 = (data * 32767).astype(np.int16)
            
            sf.write(output_path, data_int16, samplerate, subtype='PCM_16')
            return True
            
        except Exception as e:
            print(f"  âŒ è½¬æ¢å¤±è´¥: {e}")
            return False
    
    def extract_simple_features(self, audio):
        """æå–ç®€åŒ–ç‰¹å¾"""
        try:
            # 1. MFCCç‰¹å¾
            mfcc = librosa.feature.mfcc(
                y=audio, 
                sr=self.sample_rate,
                n_mfcc=self.n_mfcc,
                hop_length=self.hop_length,
                n_fft=self.n_fft
            )
            
            # 2. é¢‘è°±è´¨å¿ƒ
            spectral_centroids = librosa.feature.spectral_centroid(
                y=audio, sr=self.sample_rate, hop_length=self.hop_length
            )[0]
            
            # 3. é›¶äº¤å‰ç‡
            zcr = librosa.feature.zero_crossing_rate(
                y=audio, hop_length=self.hop_length
            )[0]
            
            # 4. RMSèƒ½é‡
            rms = librosa.feature.rms(y=audio, hop_length=self.hop_length)[0]
            
            # 5. åŸºé¢‘ä¼°è®¡ï¼ˆç®€åŒ–ç‰ˆï¼‰
            try:
                pitches, magnitudes = librosa.piptrack(
                    y=audio[:min(len(audio), self.sample_rate*10)],  # åªå–å‰10ç§’
                    sr=self.sample_rate,
                    hop_length=self.hop_length,
                    fmin=80,
                    fmax=400
                )
                pitch_values = pitches[pitches > 0]
                pitch_mean = np.mean(pitch_values) if len(pitch_values) > 0 else 0
            except:
                pitch_mean = 0
            
            # åˆå¹¶ç‰¹å¾
            features = np.concatenate([
                np.mean(mfcc, axis=1),      # MFCCå‡å€¼
                np.std(mfcc, axis=1),       # MFCCæ ‡å‡†å·®
                [np.mean(spectral_centroids)],  # é¢‘è°±è´¨å¿ƒå‡å€¼
                [np.std(spectral_centroids)],   # é¢‘è°±è´¨å¿ƒæ ‡å‡†å·®
                [np.mean(zcr)],             # é›¶äº¤å‰ç‡å‡å€¼
                [np.std(zcr)],              # é›¶äº¤å‰ç‡æ ‡å‡†å·®
                [np.mean(rms)],             # RMSå‡å€¼
                [np.std(rms)],              # RMSæ ‡å‡†å·®
                [pitch_mean]                # åŸºé¢‘å‡å€¼
            ])
            
            return features
            
        except Exception as e:
            print(f"    ç‰¹å¾æå–å¤±è´¥: {e}")
            return None
    
    def calculate_similarity(self, ref_features, target_features):
        """è®¡ç®—ç›¸ä¼¼åº¦"""
        try:
            # ç¡®ä¿ç‰¹å¾å‘é‡é•¿åº¦ä¸€è‡´
            min_len = min(len(ref_features), len(target_features))
            ref_vec = ref_features[:min_len]
            target_vec = target_features[:min_len]
            
            # ä½™å¼¦ç›¸ä¼¼åº¦
            cos_sim = 1 - cosine(ref_vec, target_vec)
            cos_sim = max(0, cos_sim)
            
            # çš®å°”é€Šç›¸å…³ç³»æ•°
            try:
                pearson_corr, _ = pearsonr(ref_vec, target_vec)
                if np.isnan(pearson_corr):
                    pearson_corr = 0
                pearson_corr = max(0, pearson_corr)
            except:
                pearson_corr = 0
            
            # ç»¼åˆåˆ†æ•°
            composite_score = 0.6 * cos_sim + 0.4 * pearson_corr
            
            return {
                'cosine': cos_sim,
                'pearson': pearson_corr,
                'composite': composite_score
            }
            
        except Exception as e:
            print(f"    ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥: {e}")
            return {'cosine': 0, 'pearson': 0, 'composite': 0}
    
    def match_voices(self, reference_audio_path, separated_voices_dir, output_dir="output"):
        """åŒ¹é…äººå£°"""
        try:
            print("ğŸ¯ ç®€åŒ–ç‰ˆäººå£°åŒ¹é…å™¨")
            print("=" * 50)
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            Path(output_dir).mkdir(exist_ok=True)
            
            # 1. åŠ è½½å‚è€ƒéŸ³é¢‘
            print("\nğŸ“ åŠ è½½å‚è€ƒéŸ³é¢‘...")
            reference_audio = self.load_audio(reference_audio_path)
            if reference_audio is None:
                return None
            
            # 2. æå–å‚è€ƒéŸ³é¢‘ç‰¹å¾
            print("ğŸ§  æå–å‚è€ƒéŸ³é¢‘ç‰¹å¾...")
            ref_features = self.extract_simple_features(reference_audio)
            if ref_features is None:
                print("âŒ å‚è€ƒéŸ³é¢‘ç‰¹å¾æå–å¤±è´¥")
                return None
            
            print(f"  å‚è€ƒç‰¹å¾ç»´åº¦: {ref_features.shape}")
            
            # 3. æŸ¥æ‰¾åˆ†ç¦»çš„äººå£°æ–‡ä»¶ï¼ˆå»é‡ï¼‰
            separated_dir = Path(separated_voices_dir)
            voice_files = set()  # ä½¿ç”¨setå»é‡
            
            # ä¼˜å…ˆé€‰æ‹©_fixedç‰ˆæœ¬
            for file in separated_dir.glob("SPEAKER_*_fixed.wav"):
                voice_files.add(file)
            
            # å¦‚æœæ²¡æœ‰_fixedç‰ˆæœ¬ï¼Œæ·»åŠ åŸç‰ˆ
            for file in separated_dir.glob("SPEAKER_*.wav"):
                fixed_version = separated_dir / f"{file.stem}_fixed.wav"
                if not fixed_version.exists():
                    voice_files.add(file)
            
            voice_files = sorted(list(voice_files))
            
            if not voice_files:
                print(f"âŒ åœ¨ {separated_voices_dir} ä¸­æœªæ‰¾åˆ°SPEAKER_*.wavæ–‡ä»¶")
                return None
            
            print(f"\nğŸ” æ‰¾åˆ° {len(voice_files)} ä¸ªäººå£°æ–‡ä»¶:")
            for vf in voice_files:
                print(f"  - {vf.name}")
            
            # 4. å¤„ç†æ¯ä¸ªäººå£°æ–‡ä»¶
            print(f"\nğŸ”„ å¤„ç†äººå£°æ–‡ä»¶...")
            results = []
            
            for i, voice_file in enumerate(voice_files):
                print(f"\n[{i+1}/{len(voice_files)}] {voice_file.name}")
                
                # è½¬æ¢æ ¼å¼
                converted_file = Path(output_dir) / f"converted_{voice_file.name}"
                if self.convert_audio_format(str(voice_file), str(converted_file)):
                    
                    # åŠ è½½è½¬æ¢åçš„éŸ³é¢‘
                    voice_audio = self.load_audio(str(converted_file))
                    if voice_audio is not None:
                        
                        # æå–ç‰¹å¾
                        voice_features = self.extract_simple_features(voice_audio)
                        if voice_features is not None:
                            
                            # è®¡ç®—ç›¸ä¼¼åº¦
                            similarity_scores = self.calculate_similarity(ref_features, voice_features)
                            
                            result = {
                                'file_path': str(voice_file),
                                'converted_path': str(converted_file),
                                'similarity_scores': similarity_scores,
                                'features': voice_features
                            }
                            results.append(result)
                            
                            print(f"    ä½™å¼¦ç›¸ä¼¼åº¦: {similarity_scores['cosine']:.3f}")
                            print(f"    çš®å°”é€Šç›¸å…³: {similarity_scores['pearson']:.3f}")
                            print(f"    ç»¼åˆåˆ†æ•°: {similarity_scores['composite']:.3f}")
            
            if not results:
                print("âŒ æ²¡æœ‰æˆåŠŸå¤„ç†çš„äººå£°æ–‡ä»¶")
                return None
            
            # 5. é€‰æ‹©æœ€ä½³åŒ¹é…
            print(f"\nğŸ† é€‰æ‹©æœ€ä½³åŒ¹é…...")
            best_match = max(results, key=lambda x: x['similarity_scores']['composite'])
            
            print(f"æœ€ä½³åŒ¹é…: {Path(best_match['file_path']).name}")
            print(f"ç»¼åˆç›¸ä¼¼åº¦åˆ†æ•°: {best_match['similarity_scores']['composite']:.3f}")
            
            # 6. ä¿å­˜æœ€ä½³åŒ¹é…ç»“æœ
            best_output_path = Path(output_dir) / "best_matched_voice.wav"
            shutil.copy2(best_match['converted_path'], best_output_path)
            
            print(f"âœ… æœ€ä½³åŒ¹é…ç»“æœä¿å­˜åˆ°: {best_output_path}")
            
            # 7. ç”Ÿæˆç®€å•æŠ¥å‘Š
            self.generate_simple_report(results, best_match, output_dir)
            
            return {
                'best_match': best_match,
                'all_results': results,
                'output_path': str(best_output_path)
            }
            
        except Exception as e:
            print(f"âŒ äººå£°åŒ¹é…å¤±è´¥: {e}")
            return None
    
    def generate_simple_report(self, results, best_match, output_dir):
        """ç”Ÿæˆç®€å•æŠ¥å‘Š"""
        try:
            print("\nğŸ“Š ç”Ÿæˆåˆ†ææŠ¥å‘Š...")
            
            # æ–‡æœ¬æŠ¥å‘Š
            report_path = Path(output_dir) / "voice_matching_report.txt"
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("äººå£°åŒ¹é…åˆ†ææŠ¥å‘Š\\n")
                f.write("=" * 30 + "\\n\\n")
                
                # æŒ‰ç»¼åˆåˆ†æ•°æ’åº
                sorted_results = sorted(results, key=lambda x: x['similarity_scores']['composite'], reverse=True)
                
                for i, result in enumerate(sorted_results):
                    file_name = Path(result['file_path']).name
                    scores = result['similarity_scores']
                    f.write(f"{i+1}. {file_name}\\n")
                    f.write(f"   ç»¼åˆåˆ†æ•°: {scores['composite']:.3f}\\n")
                    f.write(f"   ä½™å¼¦ç›¸ä¼¼åº¦: {scores['cosine']:.3f}\\n")
                    f.write(f"   çš®å°”é€Šç›¸å…³: {scores['pearson']:.3f}\\n")
                    
                    if result == best_match:
                        f.write("   *** æœ€ä½³åŒ¹é… ***\\n")
                    f.write("\\n")
                
                f.write(f"æœ€ç»ˆé€‰æ‹©: {Path(best_match['file_path']).name}\\n")
                f.write(f"æœ€é«˜åˆ†æ•°: {best_match['similarity_scores']['composite']:.3f}\\n")
            
            print(f"  ğŸ“„ æŠ¥å‘Šä¿å­˜åˆ°: {report_path}")
            
            # å¯è§†åŒ–
            plt.figure(figsize=(10, 6))
            
            file_names = [Path(result['file_path']).stem for result in results]
            composite_scores = [result['similarity_scores']['composite'] for result in results]
            
            bars = plt.bar(file_names, composite_scores, alpha=0.7)
            
            # æ ‡è®°æœ€ä½³åŒ¹é…
            best_index = results.index(best_match)
            bars[best_index].set_color('red')
            bars[best_index].set_alpha(0.9)
            
            plt.xlabel('å€™é€‰äººå£°æ–‡ä»¶')
            plt.ylabel('ç»¼åˆç›¸ä¼¼åº¦åˆ†æ•°')
            plt.title('äººå£°åŒ¹é…ç»“æœå¯¹æ¯”')
            plt.xticks(rotation=45)
            plt.grid(True, alpha=0.3)
            plt.tight_layout()
            
            viz_path = Path(output_dir) / "voice_matching_comparison.png"
            plt.savefig(viz_path, dpi=150, bbox_inches='tight')
            plt.close()
            
            print(f"  ğŸ“ˆ å›¾è¡¨ä¿å­˜åˆ°: {viz_path}")
            
        except Exception as e:
            print(f"æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {e}")

def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®è·¯å¾„
    reference_audio_path = "reference/refne2.wav"  # å‚è€ƒéŸ³é¢‘
    separated_voices_dir = "."  # åˆ†ç¦»äººå£°æ–‡ä»¶ç›®å½•
    output_dir = "output"
    
    # åˆ›å»ºåŒ¹é…å™¨
    matcher = SimpleVoiceMatcher(sample_rate=16000)
    
    # æ‰§è¡ŒåŒ¹é…
    result = matcher.match_voices(
        reference_audio_path=reference_audio_path,
        separated_voices_dir=separated_voices_dir,
        output_dir=output_dir
    )
    
    if result:
        print(f"\\nğŸ‰ äººå£°åŒ¹é…å®Œæˆ!")
        print(f"æœ€ä½³åŒ¹é…æ–‡ä»¶: {result['output_path']}")
        print(f"ç»¼åˆç›¸ä¼¼åº¦: {result['best_match']['similarity_scores']['composite']:.3f}")
        
        # æ˜¾ç¤ºæ‰€æœ‰ç»“æœæ’å
        print("\\nğŸ“Š æ‰€æœ‰å€™é€‰äººå£°æ’å:")
        sorted_results = sorted(result['all_results'], 
                              key=lambda x: x['similarity_scores']['composite'], 
                              reverse=True)
        for i, res in enumerate(sorted_results):
            name = Path(res['file_path']).name
            score = res['similarity_scores']['composite']
            print(f"  {i+1}. {name}: {score:.3f}")
    else:
        print("\\nâŒ äººå£°åŒ¹é…å¤±è´¥")

if __name__ == "__main__":
    main()
