#!/usr/bin/env python3
"""
éŸ³é¢‘é¢„å¤„ç†é™å™ªå™¨ - åŸºäºä¿¡å·ä¸ç³»ç»ŸåŸºç¡€ç†è®º
Audio Preprocessing Denoiser - Based on Signals and Systems Theory

åŒ…å«çš„ç»å…¸ä¿¡å·å¤„ç†æ–¹æ³•ï¼š
1. å‚…é‡Œå¶å˜æ¢ï¼ˆFFTï¼‰é¢‘åŸŸåˆ†æ
2. å¸¦é€šæ»¤æ³¢å™¨è®¾è®¡
3. è°±å‡æ³•é™å™ª
4. ç»´çº³æ»¤æ³¢
5. æ—¶åŸŸå’Œé¢‘åŸŸç‰¹å¾åˆ†æ
"""

import numpy as np
import matplotlib.pyplot as plt
import soundfile as sf
import librosa
from scipy import signal
from scipy.fft import fft, ifft, fftfreq
from pathlib import Path

class AudioPreprocessor:
    """éŸ³é¢‘é¢„å¤„ç†é™å™ªå™¨"""
    
    def __init__(self, sample_rate=16000):
        self.sample_rate = sample_rate
        self.nyquist = sample_rate / 2
        
    def load_audio(self, audio_path):
        """åŠ è½½éŸ³é¢‘æ–‡ä»¶"""
        try:
            audio, sr = librosa.load(audio_path, sr=self.sample_rate)
            print(f"ğŸ“ åŠ è½½éŸ³é¢‘: {audio_path}")
            print(f"   é‡‡æ ·ç‡: {sr} Hz")
            print(f"   æ—¶é•¿: {len(audio)/sr:.2f} ç§’")
            print(f"   æ ·æœ¬æ•°: {len(audio)}")
            return audio
        except Exception as e:
            print(f"âŒ éŸ³é¢‘åŠ è½½å¤±è´¥: {e}")
            return None
    
    def analyze_frequency_spectrum(self, audio, title="é¢‘è°±åˆ†æ"):
        """ä½¿ç”¨å‚…é‡Œå¶å˜æ¢åˆ†æé¢‘è°±"""
        print(f"\nğŸ” {title}")
        print("-" * 40)
        
        # 1. å¿«é€Ÿå‚…é‡Œå¶å˜æ¢ (FFT)
        N = len(audio)
        audio_fft = fft(audio)
        frequencies = fftfreq(N, 1/self.sample_rate)
        
        # 2. è®¡ç®—å¹…åº¦è°±å’Œç›¸ä½è°±
        magnitude_spectrum = np.abs(audio_fft)
        phase_spectrum = np.angle(audio_fft)
        power_spectrum = magnitude_spectrum ** 2
        
        # 3. åªå–æ­£é¢‘ç‡éƒ¨åˆ†
        positive_freq_idx = frequencies >= 0
        freq_positive = frequencies[positive_freq_idx]
        magnitude_positive = magnitude_spectrum[positive_freq_idx]
        power_positive = power_spectrum[positive_freq_idx]
        
        # 4. åˆ†æé¢‘è°±ç‰¹å¾
        dominant_freq_idx = np.argmax(magnitude_positive[1:]) + 1  # æ’é™¤ç›´æµåˆ†é‡
        dominant_frequency = freq_positive[dominant_freq_idx]
        
        # è®¡ç®—é¢‘è°±è´¨å¿ƒ
        spectral_centroid = np.sum(freq_positive * magnitude_positive) / np.sum(magnitude_positive)
        
        # è®¡ç®—å¸¦å®½
        spectral_bandwidth = np.sqrt(np.sum(((freq_positive - spectral_centroid) ** 2) * magnitude_positive) / np.sum(magnitude_positive))
        
        print(f"   ä¸»å¯¼é¢‘ç‡: {dominant_frequency:.1f} Hz")
        print(f"   é¢‘è°±è´¨å¿ƒ: {spectral_centroid:.1f} Hz") 
        print(f"   é¢‘è°±å¸¦å®½: {spectral_bandwidth:.1f} Hz")
        
        return {
            'frequencies': freq_positive,
            'magnitude': magnitude_positive,
            'power': power_positive,
            'phase': phase_spectrum,
            'dominant_freq': dominant_frequency,
            'spectral_centroid': spectral_centroid,
            'spectral_bandwidth': spectral_bandwidth
        }
      def design_bandpass_filter(self, low_freq=80, high_freq=8000, filter_order=4):
        """è®¾è®¡å¸¦é€šæ»¤æ³¢å™¨"""
        print(f"\nğŸ”§ è®¾è®¡å¸¦é€šæ»¤æ³¢å™¨")
        print("-" * 40)
        
        # å½’ä¸€åŒ–æˆªæ­¢é¢‘ç‡ï¼ˆç¡®ä¿åœ¨0-1èŒƒå›´å†…ï¼‰
        low_normalized = low_freq / self.nyquist
        high_normalized = min(high_freq / self.nyquist, 0.99)  # ç¡®ä¿å°äº1
        
        print(f"   é€šå¸¦èŒƒå›´: {low_freq} - {high_freq} Hz")
        print(f"   å½’ä¸€åŒ–é¢‘ç‡: {low_normalized:.3f} - {high_normalized:.3f}")
        print(f"   æ»¤æ³¢å™¨é˜¶æ•°: {filter_order}")
        
        # ä½¿ç”¨å·´ç‰¹æ²ƒæ–¯æ»¤æ³¢å™¨ï¼ˆå¹³å¦é€šå¸¦ç‰¹æ€§ï¼‰
        try:
            if high_normalized >= 0.99:  # å¦‚æœé«˜é¢‘æ¥è¿‘å¥ˆå¥æ–¯ç‰¹é¢‘ç‡ï¼Œä½¿ç”¨é«˜é€šæ»¤æ³¢å™¨
                b, a = signal.butter(filter_order, low_normalized, btype='high')
                print("   âœ… å·´ç‰¹æ²ƒæ–¯é«˜é€šæ»¤æ³¢å™¨è®¾è®¡å®Œæˆï¼ˆé«˜é¢‘æ¥è¿‘å¥ˆå¥æ–¯ç‰¹é¢‘ç‡ï¼‰")
            else:
                b, a = signal.butter(filter_order, [low_normalized, high_normalized], btype='band')
                print("   âœ… å·´ç‰¹æ²ƒæ–¯å¸¦é€šæ»¤æ³¢å™¨è®¾è®¡å®Œæˆ")
            
            # è®¡ç®—é¢‘ç‡å“åº”
            w, h = signal.freqz(b, a, worN=8000)
            frequencies = w * self.sample_rate / (2 * np.pi)
            
            return {
                'coefficients': (b, a),
                'frequencies': frequencies,
                'response': h,
                'type': 'butterworth'
            }
            
        except Exception as e:
            print(f"   âŒ æ»¤æ³¢å™¨è®¾è®¡å¤±è´¥: {e}")
            return None
    
    def apply_bandpass_filter(self, audio, filter_config):
        """åº”ç”¨å¸¦é€šæ»¤æ³¢å™¨"""
        try:
            print("\nğŸŒŠ åº”ç”¨å¸¦é€šæ»¤æ³¢å™¨...")
            
            b, a = filter_config['coefficients']
            
            # ä½¿ç”¨é›¶ç›¸ä½æ»¤æ³¢ï¼ˆå‰å‘å’Œåå‘æ»¤æ³¢ï¼‰
            filtered_audio = signal.filtfilt(b, a, audio)
            
            print("   âœ… å¸¦é€šæ»¤æ³¢å®Œæˆ")
            
            # åˆ†ææ»¤æ³¢æ•ˆæœ
            original_energy = np.sum(audio ** 2)
            filtered_energy = np.sum(filtered_audio ** 2)
            energy_ratio = filtered_energy / original_energy
            
            print(f"   èƒ½é‡ä¿æŒæ¯”: {energy_ratio:.3f}")
            
            return filtered_audio
            
        except Exception as e:
            print(f"   âŒ æ»¤æ³¢å™¨åº”ç”¨å¤±è´¥: {e}")
            return audio
    
    def spectral_subtraction_denoise(self, audio, noise_factor=2.0, noise_floor=0.1):
        """è°±å‡æ³•é™å™ª"""
        print(f"\nğŸ”‡ è°±å‡æ³•é™å™ª")
        print("-" * 40)
        
        try:
            # 1. çŸ­æ—¶å‚…é‡Œå¶å˜æ¢
            frame_length = 1024
            hop_length = 256
            
            # æ‰‹åŠ¨å®ç°STFTï¼ˆå±•ç¤ºå‚…é‡Œå¶å˜æ¢åŸç†ï¼‰
            n_frames = 1 + (len(audio) - frame_length) // hop_length
            stft_matrix = np.zeros((frame_length // 2 + 1, n_frames), dtype=complex)
            
            print(f"   å¸§é•¿: {frame_length} æ ·æœ¬")
            print(f"   è·³è·ƒé•¿åº¦: {hop_length} æ ·æœ¬") 
            print(f"   æ€»å¸§æ•°: {n_frames}")
            
            # æ±‰å®çª—å‡½æ•°
            window = np.hanning(frame_length)
            
            for i in range(n_frames):
                start = i * hop_length
                end = start + frame_length
                
                if end <= len(audio):
                    frame = audio[start:end] * window
                    # FFTå˜æ¢åˆ°é¢‘åŸŸ
                    frame_fft = fft(frame)
                    stft_matrix[:, i] = frame_fft[:frame_length // 2 + 1]
            
            # 2. ä¼°è®¡å™ªå£°è°±ï¼ˆä½¿ç”¨å‰å‡ å¸§ä½œä¸ºå™ªå£°å‚è€ƒï¼‰
            noise_frames = min(10, n_frames // 4)  # å‰25%çš„å¸§æˆ–å‰10å¸§
            noise_spectrum = np.mean(np.abs(stft_matrix[:, :noise_frames]), axis=1)
            
            print(f"   å™ªå£°ä¼°è®¡å¸§æ•°: {noise_frames}")
            
            # 3. è°±å‡æ³•å¤„ç†
            magnitude = np.abs(stft_matrix)
            phase = np.angle(stft_matrix)
            
            # å¯¹æ¯ä¸€å¸§åº”ç”¨è°±å‡æ³•
            enhanced_magnitude = np.zeros_like(magnitude)
            
            for i in range(n_frames):
                frame_magnitude = magnitude[:, i]
                
                # è°±å‡æ³•å…¬å¼: |S'(Ï‰)| = |Y(Ï‰)| - Î±*|N(Ï‰)|
                enhanced_frame = frame_magnitude - noise_factor * noise_spectrum
                
                # é˜²æ­¢è¿‡åº¦æŠ‘åˆ¶ï¼Œè®¾ç½®å™ªå£°åº•é™
                noise_floor_level = noise_floor * frame_magnitude
                enhanced_frame = np.maximum(enhanced_frame, noise_floor_level)
                
                enhanced_magnitude[:, i] = enhanced_frame
            
            # 4. é‡æ„æ—¶åŸŸä¿¡å·
            enhanced_stft = enhanced_magnitude * np.exp(1j * phase)
            
            # é€†STFT
            enhanced_audio = np.zeros(len(audio))
            
            for i in range(n_frames):
                start = i * hop_length
                end = start + frame_length
                
                if end <= len(audio):
                    # é€†FFTå›åˆ°æ—¶åŸŸ
                    frame_spectrum = np.concatenate([
                        enhanced_stft[:, i],
                        np.conj(enhanced_stft[-2:0:-1, i])
                    ])
                    frame_time = ifft(frame_spectrum).real
                    
                    # é‡å ç›¸åŠ 
                    enhanced_audio[start:end] += frame_time * window
            
            print("   âœ… è°±å‡æ³•é™å™ªå®Œæˆ")
            
            # è®¡ç®—ä¿¡å™ªæ¯”æ”¹å–„
            noise_power = np.mean(audio[:self.sample_rate] ** 2)  # å‰1ç§’ä½œä¸ºå™ªå£°
            signal_power = np.mean(enhanced_audio ** 2)
            snr_improvement = 10 * np.log10(signal_power / noise_power)
            
            print(f"   ä¼°è®¡SNRæ”¹å–„: {snr_improvement:.1f} dB")
            
            return enhanced_audio
            
        except Exception as e:
            print(f"   âŒ è°±å‡æ³•é™å™ªå¤±è´¥: {e}")
            return audio
    
    def wiener_filter_denoise(self, audio, noise_factor=0.1):
        """ç»´çº³æ»¤æ³¢é™å™ª"""
        print(f"\nğŸ§  ç»´çº³æ»¤æ³¢é™å™ª")
        print("-" * 40)
        
        try:
            # 1. FFTåˆ°é¢‘åŸŸ
            audio_fft = fft(audio)
            power_spectrum = np.abs(audio_fft) ** 2
            
            # 2. ä¼°è®¡å™ªå£°åŠŸç‡è°±ï¼ˆç®€åŒ–æ–¹æ³•ï¼‰
            noise_power = noise_factor * np.mean(power_spectrum)
            
            # 3. ç»´çº³æ»¤æ³¢å™¨è®¾è®¡
            # H(Ï‰) = P_s(Ï‰) / (P_s(Ï‰) + P_n(Ï‰))
            # å…¶ä¸­ P_s æ˜¯ä¿¡å·åŠŸç‡è°±ï¼ŒP_n æ˜¯å™ªå£°åŠŸç‡è°±
            wiener_filter = power_spectrum / (power_spectrum + noise_power)
            
            # 4. åº”ç”¨æ»¤æ³¢å™¨
            filtered_fft = audio_fft * wiener_filter
            filtered_audio = ifft(filtered_fft).real
            
            print(f"   å™ªå£°åŠŸç‡ä¼°è®¡: {noise_power:.2e}")
            print(f"   æ»¤æ³¢å™¨å¹³å‡å¢ç›Š: {np.mean(wiener_filter):.3f}")
            print("   âœ… ç»´çº³æ»¤æ³¢å®Œæˆ")
            
            return filtered_audio
            
        except Exception as e:
            print(f"   âŒ ç»´çº³æ»¤æ³¢å¤±è´¥: {e}")
            return audio
    
    def normalize_audio(self, audio, target_level=0.95):
        """éŸ³é¢‘å½’ä¸€åŒ–"""
        print(f"\nğŸ“ éŸ³é¢‘å½’ä¸€åŒ–")
        print("-" * 40)
        
        max_amplitude = np.max(np.abs(audio))
        if max_amplitude > 0:
            normalized_audio = audio / max_amplitude * target_level
            print(f"   åŸå§‹æœ€å¤§å¹…åº¦: {max_amplitude:.3f}")
            print(f"   ç›®æ ‡å¹…åº¦: {target_level}")
            print("   âœ… å½’ä¸€åŒ–å®Œæˆ")
            return normalized_audio
        else:
            print("   âš ï¸ éŸ³é¢‘ä¿¡å·ä¸ºé›¶ï¼Œè·³è¿‡å½’ä¸€åŒ–")
            return audio
    
    def generate_analysis_plots(self, original_audio, processed_audio, analysis_results, output_dir):
        """ç”Ÿæˆåˆ†æå›¾è¡¨"""
        try:
            print(f"\nğŸ“Š ç”Ÿæˆåˆ†æå›¾è¡¨...")
            
            fig, axes = plt.subplots(2, 3, figsize=(15, 10))
            
            # 1. æ—¶åŸŸæ³¢å½¢å¯¹æ¯”
            time_axis = np.arange(len(original_audio)) / self.sample_rate
            
            axes[0, 0].plot(time_axis, original_audio, 'b-', alpha=0.7, label='åŸå§‹éŸ³é¢‘')
            axes[0, 0].plot(time_axis, processed_audio, 'r-', alpha=0.7, label='å¤„ç†åéŸ³é¢‘')
            axes[0, 0].set_xlabel('æ—¶é—´ (ç§’)')
            axes[0, 0].set_ylabel('å¹…åº¦')
            axes[0, 0].set_title('æ—¶åŸŸæ³¢å½¢å¯¹æ¯”')
            axes[0, 0].legend()
            axes[0, 0].grid(True, alpha=0.3)
            
            # 2. åŸå§‹éŸ³é¢‘é¢‘è°±
            original_spectrum = self.analyze_frequency_spectrum(original_audio, "åŸå§‹éŸ³é¢‘é¢‘è°±")
            axes[0, 1].semilogx(original_spectrum['frequencies'], 20*np.log10(original_spectrum['magnitude'] + 1e-10))
            axes[0, 1].set_xlabel('é¢‘ç‡ (Hz)')
            axes[0, 1].set_ylabel('å¹…åº¦ (dB)')
            axes[0, 1].set_title('åŸå§‹éŸ³é¢‘é¢‘è°±')
            axes[0, 1].grid(True, alpha=0.3)
            
            # 3. å¤„ç†åéŸ³é¢‘é¢‘è°±
            processed_spectrum = self.analyze_frequency_spectrum(processed_audio, "å¤„ç†åéŸ³é¢‘é¢‘è°±")
            axes[0, 2].semilogx(processed_spectrum['frequencies'], 20*np.log10(processed_spectrum['magnitude'] + 1e-10))
            axes[0, 2].set_xlabel('é¢‘ç‡ (Hz)')
            axes[0, 2].set_ylabel('å¹…åº¦ (dB)')
            axes[0, 2].set_title('å¤„ç†åéŸ³é¢‘é¢‘è°±')
            axes[0, 2].grid(True, alpha=0.3)
            
            # 4. æ»¤æ³¢å™¨é¢‘ç‡å“åº”
            if 'filter_config' in analysis_results:
                filter_config = analysis_results['filter_config']
                axes[1, 0].semilogx(filter_config['frequencies'], 20*np.log10(np.abs(filter_config['response'])))
                axes[1, 0].set_xlabel('é¢‘ç‡ (Hz)')
                axes[1, 0].set_ylabel('å¢ç›Š (dB)')
                axes[1, 0].set_title('å¸¦é€šæ»¤æ³¢å™¨å“åº”')
                axes[1, 0].grid(True, alpha=0.3)
            
            # 5. é¢‘è°±å¯¹æ¯”
            axes[1, 1].semilogx(original_spectrum['frequencies'], 20*np.log10(original_spectrum['magnitude'] + 1e-10), 
                               'b-', alpha=0.7, label='åŸå§‹')
            axes[1, 1].semilogx(processed_spectrum['frequencies'], 20*np.log10(processed_spectrum['magnitude'] + 1e-10), 
                               'r-', alpha=0.7, label='å¤„ç†å')
            axes[1, 1].set_xlabel('é¢‘ç‡ (Hz)')
            axes[1, 1].set_ylabel('å¹…åº¦ (dB)')
            axes[1, 1].set_title('é¢‘è°±å¯¹æ¯”')
            axes[1, 1].legend()
            axes[1, 1].grid(True, alpha=0.3)
            
            # 6. åŠŸç‡è°±å¯†åº¦å¯¹æ¯”
            axes[1, 2].semilogx(original_spectrum['frequencies'], 10*np.log10(original_spectrum['power'] + 1e-10), 
                               'b-', alpha=0.7, label='åŸå§‹')
            axes[1, 2].semilogx(processed_spectrum['frequencies'], 10*np.log10(processed_spectrum['power'] + 1e-10), 
                               'r-', alpha=0.7, label='å¤„ç†å')
            axes[1, 2].set_xlabel('é¢‘ç‡ (Hz)')
            axes[1, 2].set_ylabel('åŠŸç‡ (dB)')
            axes[1, 2].set_title('åŠŸç‡è°±å¯†åº¦å¯¹æ¯”')
            axes[1, 2].legend()
            axes[1, 2].grid(True, alpha=0.3)
            
            plt.tight_layout()
            
            # ä¿å­˜å›¾è¡¨
            plot_path = Path(output_dir) / "audio_preprocessing_analysis.png"
            plt.savefig(plot_path, dpi=150, bbox_inches='tight')
            plt.close()
            
            print(f"   ğŸ“ˆ åˆ†æå›¾è¡¨ä¿å­˜åˆ°: {plot_path}")
            
        except Exception as e:
            print(f"   âŒ å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
    
    def preprocess_audio(self, input_path, output_path="output/preprocessed_audio.wav", 
                        low_freq=80, high_freq=8000, enable_spectral_subtraction=True, 
                        enable_wiener_filter=False):
        """å®Œæ•´çš„éŸ³é¢‘é¢„å¤„ç†æµç¨‹"""
        try:
            print("ğŸµ éŸ³é¢‘é¢„å¤„ç†é™å™ªå™¨")
            print("=" * 60)
            print("åŸºäºä¿¡å·ä¸ç³»ç»Ÿç†è®ºçš„éŸ³é¢‘å¤„ç†")
            print("åŒ…å«: FFTåˆ†æã€å¸¦é€šæ»¤æ³¢ã€è°±å‡æ³•é™å™ªç­‰")
            print("=" * 60)
            
            # åˆ›å»ºè¾“å‡ºç›®å½•
            output_dir = Path(output_path).parent
            output_dir.mkdir(exist_ok=True)
            
            # 1. åŠ è½½éŸ³é¢‘
            original_audio = self.load_audio(input_path)
            if original_audio is None:
                return False
            
            # 2. åŸå§‹éŸ³é¢‘é¢‘è°±åˆ†æ
            original_analysis = self.analyze_frequency_spectrum(original_audio, "åŸå§‹éŸ³é¢‘åˆ†æ")
            
            processed_audio = original_audio.copy()
            analysis_results = {}
            
            # 3. å¸¦é€šæ»¤æ³¢å™¨è®¾è®¡å’Œåº”ç”¨
            filter_config = self.design_bandpass_filter(low_freq, high_freq)
            if filter_config:
                processed_audio = self.apply_bandpass_filter(processed_audio, filter_config)
                analysis_results['filter_config'] = filter_config
            
            # 4. è°±å‡æ³•é™å™ªï¼ˆå¯é€‰ï¼‰
            if enable_spectral_subtraction:
                processed_audio = self.spectral_subtraction_denoise(processed_audio)
            
            # 5. ç»´çº³æ»¤æ³¢é™å™ªï¼ˆå¯é€‰ï¼‰
            if enable_wiener_filter:
                processed_audio = self.wiener_filter_denoise(processed_audio)
            
            # 6. éŸ³é¢‘å½’ä¸€åŒ–
            processed_audio = self.normalize_audio(processed_audio)
            
            # 7. ä¿å­˜å¤„ç†åçš„éŸ³é¢‘
            print(f"\nğŸ’¾ ä¿å­˜å¤„ç†åéŸ³é¢‘åˆ°: {output_path}")
            sf.write(output_path, processed_audio, self.sample_rate)
            
            # 8. ç”Ÿæˆåˆ†ææŠ¥å‘Šå’Œå›¾è¡¨
            self.generate_analysis_plots(original_audio, processed_audio, analysis_results, output_dir)
            
            # 9. ä¿å­˜å¤„ç†æŠ¥å‘Š
            report_path = output_dir / "preprocessing_report.txt"
            with open(report_path, 'w', encoding='utf-8') as f:
                f.write("éŸ³é¢‘é¢„å¤„ç†æŠ¥å‘Š\\n")
                f.write("=" * 30 + "\\n\\n")
                f.write(f"è¾“å…¥æ–‡ä»¶: {input_path}\\n")
                f.write(f"è¾“å‡ºæ–‡ä»¶: {output_path}\\n")
                f.write(f"é‡‡æ ·ç‡: {self.sample_rate} Hz\\n")
                f.write(f"å¸¦é€šæ»¤æ³¢èŒƒå›´: {low_freq} - {high_freq} Hz\\n")
                f.write(f"è°±å‡æ³•é™å™ª: {'æ˜¯' if enable_spectral_subtraction else 'å¦'}\\n")
                f.write(f"ç»´çº³æ»¤æ³¢: {'æ˜¯' if enable_wiener_filter else 'å¦'}\\n")
                f.write(f"\\né¢‘è°±åˆ†æç»“æœ:\\n")
                f.write(f"åŸå§‹éŸ³é¢‘ä¸»å¯¼é¢‘ç‡: {original_analysis['dominant_freq']:.1f} Hz\\n")
                f.write(f"åŸå§‹éŸ³é¢‘é¢‘è°±è´¨å¿ƒ: {original_analysis['spectral_centroid']:.1f} Hz\\n")
                f.write(f"åŸå§‹éŸ³é¢‘é¢‘è°±å¸¦å®½: {original_analysis['spectral_bandwidth']:.1f} Hz\\n")
            
            print(f"ğŸ“„ å¤„ç†æŠ¥å‘Šä¿å­˜åˆ°: {report_path}")
            print("\\nâœ… éŸ³é¢‘é¢„å¤„ç†å®Œæˆ!")
            
            return True
            
        except Exception as e:
            print(f"âŒ éŸ³é¢‘é¢„å¤„ç†å¤±è´¥: {e}")
            return False

def main():
    """ä¸»å‡½æ•°"""
    # é…ç½®å‚æ•°
    input_audio = "input/answer.wav"  # è¾“å…¥éŸ³é¢‘æ–‡ä»¶
    output_audio = "output/preprocessed_answer.wav"  # è¾“å‡ºéŸ³é¢‘æ–‡ä»¶
    
    # äººå£°é¢‘å¸¦èŒƒå›´ï¼ˆæ ¹æ®ä¿¡å·ä¸ç³»ç»Ÿç†è®ºï¼‰
    human_voice_low = 80    # Hz - åŸºé¢‘ä¸‹é™
    human_voice_high = 8000 # Hz - è°æ³¢ä¸Šé™
    
    # åˆ›å»ºé¢„å¤„ç†å™¨
    preprocessor = AudioPreprocessor(sample_rate=16000)
    
    # æ‰§è¡Œé¢„å¤„ç†
    success = preprocessor.preprocess_audio(
        input_path=input_audio,
        output_path=output_audio,
        low_freq=human_voice_low,
        high_freq=human_voice_high,
        enable_spectral_subtraction=True,  # å¯ç”¨è°±å‡æ³•
        enable_wiener_filter=False         # å¯é€‰æ‹©å¯ç”¨ç»´çº³æ»¤æ³¢
    )
    
    if success:
        print(f"\\nğŸ‰ é¢„å¤„ç†æˆåŠŸ!")
        print(f"å¤„ç†åéŸ³é¢‘: {output_audio}")
        print("å¯ä»¥ç»§ç»­è¿›è¡Œåç»­çš„äººå£°åˆ†ç¦»å’ŒåŒ¹é…å¤„ç†")
    else:
        print("\\nâŒ é¢„å¤„ç†å¤±è´¥")

if __name__ == "__main__":
    main()
