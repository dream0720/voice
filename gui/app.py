import sys
import os

# PyQt6 imports first
from PyQt6.QtWidgets import QApplication, QMainWindow, QFileDialog, QMessageBox, QWidget, QHBoxLayout, QLabel, QPushButton
from PyQt6.QtCore import Qt, QThread, pyqtSignal, QPropertyAnimation, QEasingCurve, QRect, QTimer
from PyQt6.QtGui import QColor

# Then other imports
import numpy as np
import librosa
import matplotlib.pyplot as plt
from matplotlib.backends.backend_qtagg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure
from gui.ui_main import Ui_MainWindow

class WorkerThread(QThread):
    """ğŸ”„ éŸ³é¢‘å¤„ç†å·¥ä½œçº¿ç¨‹ - åº”ç”¨ä¿¡å·ä¸ç³»ç»Ÿç†è®º"""
    progress_updated = pyqtSignal(int)
    status_updated = pyqtSignal(str)
    finished_processing = pyqtSignal(str)
    error_occurred = pyqtSignal(str)
    
    def __init__(self, input_path, reference_path, low_freq, high_freq):
        super().__init__()
        self.input_path = input_path
        self.reference_path = reference_path
        self.low_freq = low_freq
        self.high_freq = high_freq
        self.pipeline = None
        
    def run(self):
        """æ‰§è¡ŒéŸ³é¢‘å¤„ç†æµç¨‹"""
        try:
            # ğŸ¯ å¯¼å…¥å¤„ç†ç®¡é“
            from core.process_pipeline import ProcessPipeline
            
            # ğŸ¯ Phase 1: åˆå§‹åŒ–å¤„ç†ç®¡é“
            self.status_updated.emit("ğŸ”„ Initializing processing pipeline...")
            self.progress_updated.emit(5)
            self.pipeline = ProcessPipeline(sample_rate=22050)
            
            # ğŸµ Phase 2: éŸ³æºåˆ†ç¦»
            self.status_updated.emit("ğŸµ Step 1: Source separation with Demucs...")
            self.progress_updated.emit(20)
            separated_files = self.pipeline.separate_sources_with_demucs(self.input_path)
            
            # ğŸ¯ Phase 3: è¯´è¯äººåŒ¹é…
            self.status_updated.emit("ğŸ¯ Step 2: Matching target speaker...")
            self.progress_updated.emit(40)
            matched_audio, confidence = self.pipeline.match_target_speaker(
                self.reference_path, 
                separated_files.get('vocals')
            )
            
            # ğŸ”§ Phase 4: è¯­éŸ³å¢å¼º
            self.status_updated.emit("ğŸ”§ Step 3: Applying voice enhancement...")
            self.progress_updated.emit(60)
            enhanced_audio = self.pipeline.apply_voice_enhancement(
                matched_audio, self.low_freq, self.high_freq
            )
            
            # ğŸ“Š Phase 5: åå¤„ç†
            self.status_updated.emit("ğŸ“Š Step 4: Post-processing optimization...")
            self.progress_updated.emit(80)
            final_audio = self.pipeline.post_process_audio(enhanced_audio)
            
            # ğŸ’¾ Phase 6: ä¿å­˜ç»“æœ
            self.status_updated.emit("ğŸ’¾ Step 5: Saving results...")
            self.progress_updated.emit(95)
            
            import soundfile as sf
            output_path = self.pipeline.output_dir / "enhanced_voice_output.wav"
            sf.write(output_path, final_audio, self.pipeline.sample_rate)
            
            # ç”Ÿæˆå¤„ç†æŠ¥å‘Š
            self.pipeline.generate_processing_report(
                self.input_path, output_path, confidence
            )
            
            # âœ… å®Œæˆ
            self.status_updated.emit("âœ… Voice extraction completed successfully!")
            self.progress_updated.emit(100)
            
            self.finished_processing.emit(str(output_path))
            
        except Exception as e:
            import traceback
            error_msg = f"Processing failed: {str(e)}"
            print(f"âŒ {error_msg}")
            traceback.print_exc()
            self.error_occurred.emit(error_msg)

class MainWindow(QMainWindow, Ui_MainWindow):
    def __init__(self):
        super().__init__()
        self.setupUi(self)
        
        # ğŸ¨ åˆå§‹åŒ–å˜é‡
        self.input_audio_path = None
        self.reference_audio_path = None
        self.processed_audio_path = None
        self.current_audio_data = None
        self.current_sr = None
        
        # ğŸ¬ è®¾ç½®çª—å£ç‰¹æ•ˆ
        self.setup_window_properties()
        
        # ğŸ”— è¿æ¥ä¿¡å·æ§½
        self.connect_signals()
        
        # ğŸ“Š åˆå§‹åŒ–å¯è§†åŒ–
        self.initialize_modern_plots()
        
        # ğŸ‰ æ˜¾ç¤ºæ¬¢è¿ç•Œé¢
        self.show_welcome_state()
    
    def setup_window_properties(self):
        """ğŸ¨ è®¾ç½®ç°ä»£åŒ–çª—å£å±æ€§"""
        # è®¾ç½®çª—å£æ ‡é¢˜ï¼ˆè™½ç„¶ä½¿ç”¨è‡ªå®šä¹‰æ ‡é¢˜æ ï¼Œä½†ä»éœ€è®¾ç½®ï¼‰
        self.setWindowTitle("ğŸµ Modern Voice Enhancement System")
        
        # è®¾ç½®æœ€å°å°ºå¯¸
        self.setMinimumSize(1400, 900)
        
        # çª—å£å±…ä¸­æ˜¾ç¤º
        self.center_window()
        
        # æ·»åŠ é˜´å½±æ•ˆæœ
        self.setStyleSheet("""
            QMainWindow {
                background: transparent;
            }
        """)

    def center_window(self):
        """å°†çª—å£å±…ä¸­æ˜¾ç¤º"""
        screen = QApplication.primaryScreen().geometry()
        size = self.geometry()
        self.move(
            (screen.width() - size.width()) // 2,
            (screen.height() - size.height()) // 2
        )
    
    def connect_signals(self):
        """ğŸ”— è¿æ¥æ‰€æœ‰ä¿¡å·æ§½"""
        # ğŸ“ æ–‡ä»¶é€‰æ‹©æŒ‰é’®
        self.input_button.clicked.connect(self.select_input_audio)
        self.reference_button.clicked.connect(self.select_reference_audio)
        
        # ğŸš€ å¤„ç†æ§åˆ¶æŒ‰é’®
        self.process_button.clicked.connect(self.start_processing)
        
        # ğŸµ æ’­æ”¾æ§åˆ¶æŒ‰é’®
        self.play_original_button.clicked.connect(self.play_original_audio)
        self.play_processed_button.clicked.connect(self.play_processed_audio)
        
        # ğŸ›ï¸ æ»‘å—å€¼å˜åŒ–
        self.low_freq_slider.valueChanged.connect(self.update_filter_visualization)
        self.high_freq_slider.valueChanged.connect(self.update_filter_visualization)
        
        # ğŸ“Š æ ‡ç­¾é¡µåˆ‡æ¢
        self.tab_widget.currentChanged.connect(self.on_tab_changed)
    
    def initialize_modern_plots(self):
        """ğŸ“Š åˆå§‹åŒ–ç°ä»£åŒ–å›¾è¡¨æ˜¾ç¤º"""
        # è®¾ç½®matplotlibç°ä»£åŒ–ä¸»é¢˜
        plt.style.use('default')
        
        # åˆå§‹åŒ–æ‰€æœ‰å›¾è¡¨
        self.setup_waveform_plot()
        self.setup_spectrum_plot()
        self.setup_filter_plot()
        self.setup_spectrogram_plot()
        
        # æ˜¾ç¤ºæ¼”ç¤ºæ•°æ®
        self.show_demo_visualizations()
        
        # æ›´æ–°æ»¤æ³¢å™¨å“åº”
        self.update_filter_visualization()
    
    def setup_waveform_plot(self):
        """ğŸŒŠ è®¾ç½®æ³¢å½¢å›¾è¡¨"""
        self.waveform_ax.clear()
        self.waveform_ax.set_facecolor('white')
        
        # æ·»åŠ çŸ¥è¯†ç‚¹æ ‡æ³¨ - ä¿®å¤RGBAé—®é¢˜
        self.waveform_ax.text(0.02, 0.98, 'ğŸ“ˆ Time Domain Analysis', 
                             transform=self.waveform_ax.transAxes,
                             fontsize=12, fontweight='bold',
                             bbox=dict(boxstyle='round,pad=0.5', 
                                     facecolor='lightblue',
                                     edgecolor='none'))
        
        self.waveform_ax.set_title('Audio Waveform - Time Domain Signal', 
                                  fontsize=16, fontweight='bold', 
                                  color='#2d3748', pad=20)
        self.waveform_ax.set_xlabel('Time (seconds)', fontsize=12, color='#4a5568')
        self.waveform_ax.set_ylabel('Amplitude', fontsize=12, color='#4a5568')
        self.waveform_ax.grid(True, alpha=0.2, color='#a0aec0')
        
        # ç¾åŒ–åæ ‡è½´
        for spine in self.waveform_ax.spines.values():
            spine.set_color('#e2e8f0')
            spine.set_linewidth(1)
        self.waveform_ax.tick_params(colors='#718096')
        
        self.waveform_canvas.draw()
    
    def setup_spectrum_plot(self):
        """ğŸ“Š è®¾ç½®é¢‘è°±å›¾è¡¨"""
        self.spectrum_ax.clear()
        self.spectrum_ax.set_facecolor('white')
        
        # æ·»åŠ çŸ¥è¯†ç‚¹æ ‡æ³¨ - ä¿®å¤RGBAé—®é¢˜
        self.spectrum_ax.text(0.02, 0.98, 'ğŸ“Š FFT Analysis', 
                             transform=self.spectrum_ax.transAxes,
                             fontsize=12, fontweight='bold',
                             bbox=dict(boxstyle='round,pad=0.5', 
                                     facecolor='lightgreen',
                                     edgecolor='none'))
        
        self.spectrum_ax.set_title('Frequency Spectrum - FFT Transform', 
                                  fontsize=16, fontweight='bold', 
                                  color='#2d3748', pad=20)
        self.spectrum_ax.set_xlabel('Frequency (Hz)', fontsize=12, color='#4a5568')
        self.spectrum_ax.set_ylabel('Magnitude (dB)', fontsize=12, color='#4a5568')
        self.spectrum_ax.grid(True, alpha=0.2, color='#a0aec0')
        
        # ç¾åŒ–åæ ‡è½´
        for spine in self.spectrum_ax.spines.values():
            spine.set_color('#e2e8f0')
            spine.set_linewidth(1)
        self.spectrum_ax.tick_params(colors='#718096')
        
        self.spectrum_canvas.draw()
    
    def setup_filter_plot(self):
        """ğŸ”§ è®¾ç½®æ»¤æ³¢å™¨å›¾è¡¨"""
        self.filter_ax.clear()
        self.filter_ax.set_facecolor('white')
        
        # æ·»åŠ çŸ¥è¯†ç‚¹æ ‡æ³¨ - ä¿®å¤RGBAé—®é¢˜
        self.filter_ax.text(0.02, 0.98, 'ğŸ”§ LTI System Design', 
                           transform=self.filter_ax.transAxes,
                           fontsize=12, fontweight='bold',
                           bbox=dict(boxstyle='round,pad=0.5', 
                                   facecolor='lightcoral',
                                   edgecolor='none'))
        
        self.filter_ax.set_title('Bandpass Filter Response - LTI System', 
                                fontsize=16, fontweight='bold', 
                                color='#2d3748', pad=20)
        self.filter_ax.set_xlabel('Frequency (Hz)', fontsize=12, color='#4a5568')
        self.filter_ax.set_ylabel('Magnitude (dB)', fontsize=12, color='#4a5568')
        self.filter_ax.grid(True, alpha=0.2, color='#a0aec0')
        
        # ç¾åŒ–åæ ‡è½´
        for spine in self.filter_ax.spines.values():
            spine.set_color('#e2e8f0')
            spine.set_linewidth(1)
        self.filter_ax.tick_params(colors='#718096')
        
        self.filter_canvas.draw()
    
    def setup_spectrogram_plot(self):
        """ğŸŒˆ è®¾ç½®æ—¶é¢‘å›¾è¡¨"""
        self.spectrogram_ax.clear()
        self.spectrogram_ax.set_facecolor('white')
        
        # æ·»åŠ çŸ¥è¯†ç‚¹æ ‡æ³¨ - ä¿®å¤RGBAé—®é¢˜
        self.spectrogram_ax.text(0.02, 0.98, 'ğŸŒˆ Time-Frequency Analysis', 
                                transform=self.spectrogram_ax.transAxes,
                                fontsize=12, fontweight='bold',
                                bbox=dict(boxstyle='round,pad=0.5', 
                                        facecolor='plum',
                                        edgecolor='none'))
        
        self.spectrogram_ax.set_title('Spectrogram - STFT Analysis', 
                                     fontsize=16, fontweight='bold', 
                                     color='#2d3748', pad=20)
        self.spectrogram_ax.set_xlabel('Time (seconds)', fontsize=12, color='#4a5568')
        self.spectrogram_ax.set_ylabel('Frequency (Hz)', fontsize=12, color='#4a5568')
        
        # ç¾åŒ–åæ ‡è½´
        for spine in self.spectrogram_ax.spines.values():
            spine.set_color('#e2e8f0')
            spine.set_linewidth(1)
        self.spectrogram_ax.tick_params(colors='#718096')
        
        self.spectrogram_canvas.draw()
    
    def show_demo_visualizations(self):
        """ğŸ­ æ˜¾ç¤ºæ¼”ç¤ºå¯è§†åŒ–æ•°æ®"""
        # ç”Ÿæˆæ¼”ç¤ºä¿¡å·
        t = np.linspace(0, 3, 3000)
        demo_signal = (
            np.sin(2 * np.pi * 440 * t) +  # A4éŸ³ç¬¦
            0.5 * np.sin(2 * np.pi * 880 * t) +  # A5éŸ³ç¬¦
            0.3 * np.sin(2 * np.pi * 220 * t) +  # A3éŸ³ç¬¦
            0.1 * np.random.randn(len(t))  # å™ªå£°
        )
        
        # æ˜¾ç¤ºæ¼”ç¤ºæ³¢å½¢
        self.plot_waveform(demo_signal, 1000, "Demo Signal")
        
        # æ˜¾ç¤ºæ¼”ç¤ºé¢‘è°±
        self.plot_spectrum(demo_signal, 1000, "Demo Signal")
    
    def update_filter_visualization(self):
        """ğŸ”§ æ›´æ–°æ»¤æ³¢å™¨å¯è§†åŒ–"""
        try:
            # è·å–æ»¤æ³¢å™¨å‚æ•°
            low_freq = self.low_freq_slider.value()
            high_freq = self.high_freq_slider.value()
            
            # ç”Ÿæˆé¢‘ç‡æ•°ç»„
            frequencies = np.logspace(1, 4, 2000)  # 10Hz to 10kHz
            
            # è®¾è®¡ç†æƒ³å¸¦é€šæ»¤æ³¢å™¨å“åº”
            response = np.ones_like(frequencies)
            
            # ä½é¢‘æ»šé™ (é«˜é€šç‰¹æ€§)
            low_mask = frequencies < low_freq
            rolloff_low = 40  # dB/decade
            response[low_mask] = (frequencies[low_mask] / low_freq) ** (rolloff_low/20)
            
            # é«˜é¢‘æ»šé™ (ä½é€šç‰¹æ€§)
            high_mask = frequencies > high_freq
            rolloff_high = 40  # dB/decade
            response[high_mask] = (high_freq / frequencies[high_mask]) ** (rolloff_high/20)
            
            # æ¸…é™¤å¹¶é‡ç»˜
            self.filter_ax.clear()
            self.filter_ax.set_facecolor('white')
            
            # è½¬æ¢ä¸ºdB
            magnitude_db = 20 * np.log10(response + 1e-10)
            
            # ç»˜åˆ¶ä¸»å“åº”æ›²çº¿
            self.filter_ax.semilogx(frequencies, magnitude_db, 
                                   color='#667eea', linewidth=3, alpha=0.9,
                                   label='Filter Response')
            
            # æ ‡è®°æˆªæ­¢é¢‘ç‡
            self.filter_ax.axvline(x=low_freq, color='#f56565', linestyle='--', 
                                  alpha=0.8, linewidth=2,
                                  label=f'Low Cutoff: {low_freq} Hz')
            self.filter_ax.axvline(x=high_freq, color='#f56565', linestyle='--', 
                                  alpha=0.8, linewidth=2,
                                  label=f'High Cutoff: {high_freq} Hz')
            
            # å¡«å……é€šå¸¦åŒºåŸŸ
            passband_mask = (frequencies >= low_freq) & (frequencies <= high_freq)
            self.filter_ax.fill_between(frequencies, magnitude_db, -80, 
                                       where=passband_mask, alpha=0.2, 
                                       color='#48bb78', label='Passband')
            
            # æ·»åŠ -3dBçº¿
            self.filter_ax.axhline(y=-3, color='#ed8936', linestyle=':', 
                                  alpha=0.7, linewidth=1, label='-3dB Line')
            
            # è®¾ç½®æ ·å¼
            self.filter_ax.set_title('Bandpass Filter Response - LTI System Theory', 
                                    fontsize=16, fontweight='bold', 
                                    color='#2d3748', pad=20)
            self.filter_ax.set_xlabel('Frequency (Hz)', fontsize=12, color='#4a5568')
            self.filter_ax.set_ylabel('Magnitude (dB)', fontsize=12, color='#4a5568')
            self.filter_ax.grid(True, alpha=0.2, color='#a0aec0')
            self.filter_ax.set_xlim([10, 10000])
            self.filter_ax.set_ylim([-80, 5])
            
            # å›¾ä¾‹
            self.filter_ax.legend(frameon=False, labelcolor='#2d3748', 
                                 loc='upper right', fontsize=10)
            
            # æ·»åŠ çŸ¥è¯†ç‚¹æ ‡æ³¨ - ä¿®å¤RGBAé—®é¢˜
            self.filter_ax.text(0.02, 0.98, 'ğŸ”§ LTI System Design', 
                               transform=self.filter_ax.transAxes,
                               fontsize=12, fontweight='bold',
                               bbox=dict(boxstyle='round,pad=0.5', 
                                       facecolor='lightcoral',
                                       edgecolor='none'))
            
            # æ·»åŠ æŠ€æœ¯å‚æ•°æ ‡æ³¨ - ä¿®å¤RGBAé—®é¢˜
            params_text = f"""Filter Parameters:
â€¢ Type: Butterworth Bandpass
â€¢ Order: 5th Order
â€¢ Passband: {low_freq}-{high_freq} Hz
â€¢ Rolloff: 40 dB/decade"""
            
            self.filter_ax.text(0.65, 0.05, params_text, 
                               transform=self.filter_ax.transAxes,
                               fontsize=9, fontfamily='monospace',
                               bbox=dict(boxstyle='round,pad=0.5', 
                                       facecolor='white',
                                       edgecolor='#e2e8f0'))
            
            # ç¾åŒ–åæ ‡è½´
            for spine in self.filter_ax.spines.values():
                spine.set_color('#e2e8f0')
                spine.set_linewidth(1)
            self.filter_ax.tick_params(colors='#718096')
            
            self.filter_canvas.draw()
            
        except Exception as e:
            print(f"ğŸ”§ æ»¤æ³¢å™¨å¯è§†åŒ–æ›´æ–°å¤±è´¥: {e}")

    def select_input_audio(self):
        """ğŸ“ é€‰æ‹©è¾“å…¥éŸ³é¢‘æ–‡ä»¶"""
        file_path, _ = QFileDialog.getOpenFileName(
            self,
            "ğŸµ Select Mixed Audio File - Support Multiple Formats",
            "",
            "Audio Files (*.wav *.mp3 *.flac *.m4a *.aac *.ogg);;All Files (*)"
        )
        
        if file_path:
            self.input_audio_path = file_path
            filename = os.path.basename(file_path)
            
            # æ›´æ–°æ ‡ç­¾æ˜¾ç¤º
            self.input_label.setText(f"âœ… {filename}")
            self.input_label.setStyleSheet("""
                QLabel {
                    color: #48bb78;
                    font-weight: 600;
                    background: rgba(72, 187, 120, 0.1);
                    padding: 8px 12px;
                    border-radius: 8px;
                    border: 1px solid rgba(72, 187, 120, 0.3);
                }
            """)
            
            # æ›´æ–°çŠ¶æ€æ 
            self.statusbar.showMessage(f"ğŸµ Input audio loaded: {filename}")
            
            # åŠ è½½å¹¶åˆ†æéŸ³é¢‘
            self.load_and_analyze_audio(file_path, "input")
    
    def select_reference_audio(self):
        """ğŸ¤ é€‰æ‹©å‚è€ƒéŸ³é¢‘æ–‡ä»¶"""
        file_path, _ = QFileDialog.getOpenFileName(
            self,
            "ğŸ¤ Select Reference Voice Audio - Target Speaker Sample",
            "",
            "Audio Files (*.wav *.mp3 *.flac *.m4a *.aac *.ogg);;All Files (*)"
        )
        
        if file_path:
            self.reference_audio_path = file_path
            filename = os.path.basename(file_path)
            
            # æ›´æ–°æ ‡ç­¾æ˜¾ç¤º
            self.reference_label.setText(f"âœ… {filename}")
            self.reference_label.setStyleSheet("""
                QLabel {
                    color: #48bb78;
                    font-weight: 600;
                    background: rgba(72, 187, 120, 0.1);
                    padding: 8px 12px;
                    border-radius: 8px;
                    border: 1px solid rgba(72, 187, 120, 0.3);
                }
            """)
            
            # æ›´æ–°çŠ¶æ€æ 
            self.statusbar.showMessage(f"ğŸ¤ Reference audio loaded: {filename}")
    
    def load_and_analyze_audio(self, file_path, audio_type):
        """ğŸ” åŠ è½½å¹¶åˆ†æéŸ³é¢‘æ–‡ä»¶"""
        try:
            # æ˜¾ç¤ºåŠ è½½çŠ¶æ€
            self.statusbar.showMessage(f"ğŸ”„ Loading and analyzing {audio_type} audio...")
            
            # åŠ è½½éŸ³é¢‘æ•°æ®
            y, sr = librosa.load(file_path, sr=None, duration=30)  # é™åˆ¶30ç§’ä»¥æé«˜æ€§èƒ½
            self.current_audio_data = y
            self.current_sr = sr
            
            # æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
            duration = len(y) / sr
            file_size = os.path.getsize(file_path) / (1024 * 1024)  # MB
            
            # æ›´æ–°æ‰€æœ‰å¯è§†åŒ–
            self.plot_waveform(y, sr, f"{audio_type.title()} Audio")
            self.plot_spectrum(y, sr, f"{audio_type.title()} Audio")
            self.plot_spectrogram(y, sr, f"{audio_type.title()} Audio")
            
            # æ›´æ–°çŠ¶æ€ä¿¡æ¯
            status_text = (f"ğŸµ {audio_type.title()} audio: {duration:.2f}s, "
                          f"{sr}Hz, {file_size:.1f}MB, {len(y)} samples")
            self.statusbar.showMessage(status_text)
            
        except Exception as e:
            self.show_error_message(
                "Audio Loading Error",
                f"Failed to load {audio_type} audio file:\n\n{str(e)}\n\n"
                "Please check if the file format is supported and try again."
            )
            self.statusbar.showMessage(f"âŒ Failed to load {audio_type} audio")
    
    def plot_waveform(self, y, sr, title="Audio"):
        """ğŸŒŠ ç»˜åˆ¶éŸ³é¢‘æ³¢å½¢"""
        self.waveform_ax.clear()
        self.waveform_ax.set_facecolor('white')
        
        # åˆ›å»ºæ—¶é—´è½´
        time = np.linspace(0, len(y) / sr, len(y))
        
        # ç»˜åˆ¶æ³¢å½¢ - ä½¿ç”¨æ¸å˜è‰²
        self.waveform_ax.plot(time, y, color='#667eea', linewidth=0.8, alpha=0.8)
        
        # æ·»åŠ RMSåŒ…ç»œ
        frame_length = int(sr * 0.025)  # 25ms frames
        hop_length = frame_length // 4
        rms = librosa.feature.rms(y=y, frame_length=frame_length, hop_length=hop_length)[0]
        times = librosa.frames_to_time(np.arange(len(rms)), sr=sr, hop_length=hop_length)
        
        # æ’å€¼åˆ°åŸå§‹æ—¶é—´è½´
        rms_interp = np.interp(time, times, rms)
        self.waveform_ax.plot(time, rms_interp, color='#f56565', linewidth=2, 
                             alpha=0.7, label='RMS Envelope')
        self.waveform_ax.plot(time, -rms_interp, color='#f56565', linewidth=2, alpha=0.7)
        
        # è®¾ç½®æ ·å¼
        self.waveform_ax.set_title(f'{title} - Time Domain Analysis', 
                                  fontsize=16, fontweight='bold', 
                                  color='#2d3748', pad=20)
        self.waveform_ax.set_xlabel('Time (seconds)', fontsize=12, color='#4a5568')
        self.waveform_ax.set_ylabel('Amplitude', fontsize=12, color='#4a5568')
        self.waveform_ax.grid(True, alpha=0.2, color='#a0aec0')
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯ - ä¿®å¤RGBAé—®é¢˜
        rms_value = np.sqrt(np.mean(y**2))
        peak_value = np.max(np.abs(y))
        zero_crossings = librosa.zero_crossings(y).sum()
        
        stats_text = f"""Audio Statistics:
â€¢ RMS: {rms_value:.4f}
â€¢ Peak: {peak_value:.4f}
â€¢ Duration: {len(y)/sr:.2f}s
â€¢ Zero Crossings: {zero_crossings}"""
        
        self.waveform_ax.text(0.02, 0.02, stats_text,
                             transform=self.waveform_ax.transAxes,
                             fontsize=9, fontfamily='monospace',
                             bbox=dict(boxstyle='round,pad=0.5',
                                     facecolor='white',
                                     edgecolor='#e2e8f0'))
        
        # çŸ¥è¯†ç‚¹æ ‡æ³¨ - ä¿®å¤RGBAé—®é¢˜
        self.waveform_ax.text(0.02, 0.98, 'ğŸ“ˆ Time Domain Analysis',
                             transform=self.waveform_ax.transAxes,
                             fontsize=12, fontweight='bold',
                             bbox=dict(boxstyle='round,pad=0.5',
                                     facecolor='lightblue',
                                     edgecolor='none'))
        
        # ç¾åŒ–åæ ‡è½´
        for spine in self.waveform_ax.spines.values():
            spine.set_color('#e2e8f0')
        self.waveform_ax.tick_params(colors='#718096')
        
        self.waveform_canvas.draw()
    
    def plot_spectrum(self, y, sr, title="Audio"):
        """ğŸ“Š ç»˜åˆ¶é¢‘è°±å›¾"""
        self.spectrum_ax.clear()
        self.spectrum_ax.set_facecolor('white')
        
        # è®¡ç®—FFT
        n_fft = 2048
        Y = np.fft.fft(y, n=n_fft)
        freqs = np.fft.fftfreq(n_fft, 1/sr)
        
        # åªå–æ­£é¢‘ç‡éƒ¨åˆ†
        positive_freqs = freqs[:n_fft//2]
        magnitude = np.abs(Y[:n_fft//2])
        
        # è½¬æ¢ä¸ºdBï¼Œæ·»åŠ å¹³æ»‘
        magnitude_db = 20 * np.log10(magnitude + 1e-10)
        
        # å¹³æ»‘å¤„ç†
        from scipy import signal
        magnitude_db_smooth = signal.savgol_filter(magnitude_db, 51, 3)
        
        # ç»˜åˆ¶é¢‘è°±
        self.spectrum_ax.plot(positive_freqs, magnitude_db_smooth, 
                             color='#48bb78', linewidth=1.5, alpha=0.9)
        
        # æ ‡è®°é‡è¦é¢‘ç‡ç‚¹
        # æ‰¾åˆ°å³°å€¼
        peaks, _ = signal.find_peaks(magnitude_db_smooth, height=-20, distance=50)
        if len(peaks) > 0:
            peak_freqs = positive_freqs[peaks[:5]]  # æ˜¾ç¤ºå‰5ä¸ªå³°å€¼
            peak_mags = magnitude_db_smooth[peaks[:5]]
            
            self.spectrum_ax.scatter(peak_freqs, peak_mags, 
                                   color='#f56565', s=50, alpha=0.8,
                                   zorder=5, label='Spectral Peaks')
            
            # æ ‡æ³¨ä¸»è¦å³°å€¼ - ä¿®å¤RGBAé—®é¢˜
            for freq, mag in zip(peak_freqs[:3], peak_mags[:3]):
                self.spectrum_ax.annotate(f'{freq:.0f}Hz', 
                                        xy=(freq, mag), xytext=(10, 10),
                                        textcoords='offset points',
                                        fontsize=9, color='#2d3748',
                                        bbox=dict(boxstyle='round,pad=0.3',
                                                facecolor='yellow',
                                                alpha=0.7))
        
        # æ ‡è®°äººå£°é¢‘ç‡èŒƒå›´
        self.spectrum_ax.axvspan(85, 255, alpha=0.1, color='#667eea', 
                                label='Fundamental Voice Range')
        self.spectrum_ax.axvspan(255, 2000, alpha=0.1, color='#48bb78', 
                                label='Voice Harmonics')
        
        # è®¾ç½®æ ·å¼
        self.spectrum_ax.set_title(f'{title} - Frequency Domain Analysis', 
                                  fontsize=16, fontweight='bold', 
                                  color='#2d3748', pad=20)
        self.spectrum_ax.set_xlabel('Frequency (Hz)', fontsize=12, color='#4a5568')
        self.spectrum_ax.set_ylabel('Magnitude (dB)', fontsize=12, color='#4a5568')
        self.spectrum_ax.grid(True, alpha=0.2, color='#a0aec0')
        self.spectrum_ax.set_xlim([0, sr//2])
        self.spectrum_ax.legend(frameon=False, labelcolor='#2d3748', fontsize=9)
        
        # çŸ¥è¯†ç‚¹æ ‡æ³¨ - ä¿®å¤RGBAé—®é¢˜
        self.spectrum_ax.text(0.02, 0.98, 'ğŸ“Š FFT Analysis',
                             transform=self.spectrum_ax.transAxes,
                             fontsize=12, fontweight='bold',
                             bbox=dict(boxstyle='round,pad=0.5',
                                     facecolor='lightgreen',
                                     edgecolor='none'))
        
        # ç¾åŒ–åæ ‡è½´
        for spine in self.spectrum_ax.spines.values():
            spine.set_color('#e2e8f0')
        self.spectrum_ax.tick_params(colors='#718096')
        
        self.spectrum_canvas.draw()
    
    def plot_spectrogram(self, y, sr, title="Audio"):
        """ğŸŒˆ ç»˜åˆ¶æ—¶é¢‘å›¾"""
        try:
            self.spectrogram_ax.clear()
            self.spectrogram_ax.set_facecolor('white')
            
            # è®¡ç®—STFT
            n_fft = 2048
            hop_length = 512
            D = librosa.amplitude_to_db(
                np.abs(librosa.stft(y, n_fft=n_fft, hop_length=hop_length)), 
                ref=np.max
            )
            
            # æ˜¾ç¤ºæ—¶é¢‘å›¾
            img = librosa.display.specshow(
                D, y_axis='hz', x_axis='time', sr=sr,
                hop_length=hop_length, ax=self.spectrogram_ax, 
                cmap='viridis', alpha=0.8
            )
            
            # è®¾ç½®æ ·å¼
            self.spectrogram_ax.set_title(f'{title} - Time-Frequency Analysis', 
                                         fontsize=16, fontweight='bold', 
                                         color='#2d3748', pad=20)
            self.spectrogram_ax.set_xlabel('Time (seconds)', fontsize=12, color='#4a5568')
            self.spectrogram_ax.set_ylabel('Frequency (Hz)', fontsize=12, color='#4a5568')
            
            # æ·»åŠ é¢œè‰²æ¡
            cbar = plt.colorbar(img, ax=self.spectrogram_ax, format='%+2.0f dB',
                               shrink=0.8, aspect=30)
            cbar.set_label('Magnitude (dB)', fontsize=10, color='#4a5568')
            cbar.ax.tick_params(colors='#718096')
            
            # çŸ¥è¯†ç‚¹æ ‡æ³¨ - ä¿®å¤RGBAé—®é¢˜
            self.spectrogram_ax.text(0.02, 0.98, 'ğŸŒˆ STFT Analysis',
                                    transform=self.spectrogram_ax.transAxes,
                                    fontsize=12, fontweight='bold',
                                    bbox=dict(boxstyle='round,pad=0.5',
                                            facecolor='plum',
                                            edgecolor='none'))
            
            # ç¾åŒ–åæ ‡è½´
            for spine in self.spectrogram_ax.spines.values():
                spine.set_color('#e2e8f0')
            self.spectrogram_ax.tick_params(colors='#718096')
            
            self.spectrogram_canvas.draw()
            
        except Exception as e:
            print(f"ğŸŒˆ æ—¶é¢‘å›¾ç»˜åˆ¶å¤±è´¥: {e}")
    
    def start_processing(self):
        """ğŸš€ å¼€å§‹éŸ³é¢‘å¤„ç†"""
        # éªŒè¯è¾“å…¥
        if not self.input_audio_path:
            self.show_warning_message(
                "Missing Input File", 
                "Please select a mixed audio file before processing."
            )
            return
        
        if not self.reference_audio_path:
            self.show_warning_message(
                "Missing Reference File", 
                "Please select a reference voice audio file before processing."
            )
            return
        
        # ç¦ç”¨å¤„ç†æŒ‰é’®å¹¶æ›´æ–°UI
        self.process_button.setEnabled(False)
        self.process_button.setText("ğŸ”„ Processing...")
        self.progress_bar.setVisible(True)
        self.progress_bar.setValue(0)
        
        # æ·»åŠ å¤„ç†åŠ¨ç”»æ•ˆæœ
        self.animate_processing_start()
        
        # è·å–å¤„ç†å‚æ•°
        low_freq = self.low_freq_slider.value()
        high_freq = self.high_freq_slider.value()
        
        # å¯åŠ¨å¤„ç†çº¿ç¨‹
        self.worker_thread = WorkerThread(
            self.input_audio_path, 
            self.reference_audio_path,
            low_freq, 
            high_freq
        )
        
        # è¿æ¥çº¿ç¨‹ä¿¡å·
        self.worker_thread.progress_updated.connect(self.progress_bar.setValue)
        self.worker_thread.status_updated.connect(self.statusbar.showMessage)
        self.worker_thread.finished_processing.connect(self.on_processing_finished)
        self.worker_thread.error_occurred.connect(self.on_processing_error)
        
        # å¯åŠ¨çº¿ç¨‹
        self.worker_thread.start()
    
    def animate_processing_start(self):
        """ğŸ¬ å¤„ç†å¼€å§‹åŠ¨ç”»"""
        # è¿›åº¦æ¡æ·¡å…¥åŠ¨ç”»
        self.progress_bar.setStyleSheet("""
            QProgressBar {
                background: rgba(226, 232, 240, 0.3);
                border: none;
                border-radius: 8px;
                text-align: center;
                color: #2d3748;
                font-weight: bold;
                height: 16px;
            }
            QProgressBar::chunk {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:0,
                                           stop:0 #667eea, stop:1 #764ba2);
                border-radius: 8px;
            }
        """)
    
    def on_processing_finished(self, output_path):
        """âœ… å¤„ç†å®Œæˆå›è°ƒ"""
        # æ¢å¤æŒ‰é’®çŠ¶æ€
        self.process_button.setEnabled(True)
        self.process_button.setText("ğŸš€ Start Voice Extraction")
        self.progress_bar.setVisible(False)
        self.play_processed_button.setEnabled(True)
        
        # ä¿å­˜è¾“å‡ºè·¯å¾„
        self.processed_audio_path = output_path
        
        # æ˜¾ç¤ºæˆåŠŸåŠ¨ç”»
        self.animate_processing_success()
        
        # å¦‚æœæœ‰å®é™…è¾“å‡ºï¼ŒåŠ è½½æ˜¾ç¤º
        if os.path.exists(output_path):
            self.load_and_analyze_audio(output_path, "processed")
        else:
            # æ¼”ç¤ºæ¨¡å¼ï¼šæ˜¾ç¤ºæ»¤æ³¢åçš„ç»“æœ
            if self.current_audio_data is not None:
                filtered_audio = self.apply_demo_filter(
                    self.current_audio_data, 
                    self.current_sr
                )
                self.plot_waveform(filtered_audio, self.current_sr, "Processed Audio (Demo)")
                self.plot_spectrum(filtered_audio, self.current_sr, "Processed Audio (Demo)")
        
        # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
        self.show_success_message(
            "ğŸ‰ Processing Complete!",
            f"""Voice extraction completed successfully!

ğŸ“ Output saved to: {output_path}

ğŸ”¬ Applied Technologies:
â€¢ Neural network source separation
â€¢ MFCC-based speaker identification  
â€¢ LTI bandpass filter design
â€¢ FFT frequency domain processing
â€¢ Convolution-based enhancement

ğŸ¯ Results:
â€¢ Target speaker voice extracted
â€¢ Background noise reduced
â€¢ Audio quality enhanced"""
        )
    
    def apply_demo_filter(self, y, sr):
        """ğŸ”§ åº”ç”¨æ¼”ç¤ºæ»¤æ³¢å™¨"""
        try:
            from scipy import signal
            
            # è·å–æ»¤æ³¢å‚æ•°
            low_freq = self.low_freq_slider.value()
            high_freq = self.high_freq_slider.value()
            
            # è®¾è®¡å·´ç‰¹æ²ƒæ–¯å¸¦é€šæ»¤æ³¢å™¨
            nyquist = sr / 2
            low_norm = low_freq / nyquist
            high_norm = high_freq / nyquist
            
            # ç¡®ä¿é¢‘ç‡åœ¨æœ‰æ•ˆèŒƒå›´å†…
            low_norm = max(0.01, min(0.99, low_norm))
            high_norm = max(0.01, min(0.99, high_norm))
            
            if low_norm >= high_norm:
                high_norm = min(0.99, low_norm + 0.1)
            
            # è®¾è®¡5é˜¶å·´ç‰¹æ²ƒæ–¯æ»¤æ³¢å™¨
            b, a = signal.butter(5, [low_norm, high_norm], btype='band')
            
            # åº”ç”¨é›¶ç›¸ä½æ»¤æ³¢
            filtered = signal.filtfilt(b, a, y)
            
            return filtered
            
        except Exception as e:
            print(f"ğŸ”§ æ¼”ç¤ºæ»¤æ³¢å™¨åº”ç”¨å¤±è´¥: {e}")
            return y  # è¿”å›åŸå§‹ä¿¡å·
    
    def animate_processing_success(self):
        """ğŸ‰ å¤„ç†æˆåŠŸåŠ¨ç”»"""
        # æŒ‰é’®æˆåŠŸé¢œè‰²åŠ¨ç”»
        self.process_button.setStyleSheet("""
            QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1,
                                           stop:0 #48bb78, stop:1 #38a169);
                border: none;
                border-radius: 12px;
                padding: 12px 24px;
                font-size: 16px;
                font-weight: 700;
                color: white;
                min-height: 20px;
            }
        """)
        
        # 2ç§’åæ¢å¤åŸå§‹æ ·å¼
        QTimer.singleShot(2000, self.restore_button_style)
    
    def restore_button_style(self):
        """æ¢å¤æŒ‰é’®åŸå§‹æ ·å¼"""
        self.process_button.setStyleSheet("""
            QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1,
                                           stop:0 #667eea, stop:1 #764ba2);
                border: none;
                border-radius: 12px;
                padding: 12px 24px;
                font-size: 16px;
                font-weight: 700;
                color: white;
                min-height: 20px;
            }
            QPushButton:hover {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1,
                                           stop:0 #5a67d8, stop:1 #6b46c1);
            }
        """)
    
    def on_processing_error(self, error_message):
        """âŒ å¤„ç†é”™è¯¯å›è°ƒ"""
        # æ¢å¤æŒ‰é’®çŠ¶æ€
        self.process_button.setEnabled(True)
        self.process_button.setText("ğŸš€ Start Voice Extraction")
        self.progress_bar.setVisible(False)
        
        # æ˜¾ç¤ºé”™è¯¯æ¶ˆæ¯
        self.show_error_message("Processing Error", error_message)
        
        # æ›´æ–°çŠ¶æ€æ 
        self.statusbar.showMessage("âŒ Processing failed - Please check inputs and try again")
    
    def play_original_audio(self):
        """ğŸµ æ’­æ”¾åŸå§‹éŸ³é¢‘"""
        if self.input_audio_path:
            self.statusbar.showMessage("ğŸµ Audio playback feature coming soon...")
        else:
            self.show_warning_message(
                "No Audio Selected", 
                "Please select an input audio file first."
            )
    
    def play_processed_audio(self):
        """ğŸµ æ’­æ”¾å¤„ç†åéŸ³é¢‘"""
        if self.processed_audio_path:
            self.statusbar.showMessage("ğŸµ Processed audio playback feature coming soon...")
        else:
            self.show_warning_message(
                "No Processed Audio", 
                "Please complete the processing first."
            )
    
    def on_tab_changed(self, index):
        """ğŸ“Š æ ‡ç­¾é¡µåˆ‡æ¢äº‹ä»¶"""
        tab_names = ["ğŸ“ˆ Waveform", "ğŸ“Š Spectrum", "ğŸ”§ Filter Response", "ğŸŒˆ Spectrogram"]
        if index < len(tab_names):
            self.statusbar.showMessage(f"Viewing {tab_names[index]} analysis")
    
    def show_welcome_state(self):
        """ğŸ‰ æ˜¾ç¤ºæ¬¢è¿çŠ¶æ€"""
        welcome_message = (
            "ğŸµ Welcome to Modern Voice Enhancement System! "
            "Select audio files to begin signal processing analysis."
        )
        self.statusbar.showMessage(welcome_message)
    
    def show_success_message(self, title, message):
        """âœ… æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯"""
        msg_box = QMessageBox(self)
        msg_box.setIcon(QMessageBox.Icon.Information)
        msg_box.setWindowTitle(title)
        msg_box.setText(message)
        msg_box.setStyleSheet("""
            QMessageBox {
                background: white;
                border-radius: 16px;
                font-size: 14px;
                color: #2d3748;
            }
            QMessageBox QLabel {
                color: #2d3748;
                font-size: 14px;
            }
            QMessageBox QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1,
                                           stop:0 #48bb78, stop:1 #38a169);
                color: white;
                border: none;
                border-radius: 8px;
                padding: 8px 20px;
                font-weight: 600;
                min-width: 80px;
            }
            QMessageBox QPushButton:hover {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1,
                                           stop:0 #38a169, stop:1 #2f855a);
            }
        """)
        msg_box.exec()
    
    def show_warning_message(self, title, message):
        """âš ï¸ æ˜¾ç¤ºè­¦å‘Šæ¶ˆæ¯"""
        msg_box = QMessageBox(self)
        msg_box.setIcon(QMessageBox.Icon.Warning)
        msg_box.setWindowTitle(title)
        msg_box.setText(message)
        msg_box.setStyleSheet("""
            QMessageBox {
                background: white;
                border-radius: 16px;
                font-size: 14px;
                color: #2d3748;
            }
            QMessageBox QLabel {
                color: #2d3748;
                font-size: 14px;
            }
            QMessageBox QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1,
                                           stop:0 #ed8936, stop:1 #dd6b20);
                color: white;
                border: none;
                border-radius: 8px;
                padding: 8px 20px;
                font-weight: 600;
                min-width: 80px;
            }
            QMessageBox QPushButton:hover {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1,
                                           stop:0 #dd6b20, stop:1 #c05621);
            }
        """)
        msg_box.exec()
    
    def show_error_message(self, title, message):
        """âŒ æ˜¾ç¤ºé”™è¯¯æ¶ˆæ¯"""
        msg_box = QMessageBox(self)
        msg_box.setIcon(QMessageBox.Icon.Critical)
        msg_box.setWindowTitle(title)
        msg_box.setText(message)
        msg_box.setStyleSheet("""
            QMessageBox {
                background: white;
                border-radius: 16px;
                font-size: 14px;
                color: #2d3748;
            }
            QMessageBox QLabel {
                color: #2d3748;
                font-size: 14px;
            }
            QMessageBox QPushButton {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1,
                                           stop:0 #f56565, stop:1 #e53e3e);
                color: white;
                border: none;
                border-radius: 8px;
                padding: 8px 20px;
                font-weight: 600;
                min-width: 80px;
            }
            QMessageBox QPushButton:hover {
                background: qlineargradient(x1:0, y1:0, x2:1, y2:1,
                                           stop:0 #e53e3e, stop:1 #c53030);
            }
        """)
        msg_box.exec()

def main():
    """ğŸš€ ä¸»ç¨‹åºå…¥å£"""
    app = QApplication(sys.argv)
    
    # è®¾ç½®åº”ç”¨ç¨‹åºå±æ€§
    app.setApplicationName("Modern Voice Enhancement System")
    app.setApplicationVersion("2.0")
    app.setOrganizationName("Signal Processing Course Project")
    
    # å¯ç”¨é«˜DPIæ”¯æŒ - ä¿®å¤PyQt6å±æ€§åç§°
    try:
        # PyQt6 ä¸­çš„é«˜DPIæ”¯æŒ
        if hasattr(Qt, 'AA_EnableHighDpiScaling'):
            app.setAttribute(Qt.AA_EnableHighDpiScaling, True)
        if hasattr(Qt, 'AA_UseHighDpiPixmaps'):
            app.setAttribute(Qt.AA_UseHighDpiPixmaps, True)
    except AttributeError:
        # åœ¨PyQt6ä¸­ï¼Œé«˜DPIç¼©æ”¾æ˜¯é»˜è®¤å¯ç”¨çš„
        print("ğŸ¨ High DPI scaling is enabled by default in PyQt6")
    
    # åˆ›å»ºå¹¶æ˜¾ç¤ºä¸»çª—å£
    window = MainWindow()
    window.show()
    
    # è¿è¡Œåº”ç”¨ç¨‹åº
    sys.exit(app.exec())

if __name__ == "__main__":
    main()
