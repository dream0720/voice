ğŸš€ Voice Processing Suite åˆå§‹åŒ–æˆåŠŸï¼
ğŸ“‹ åŠŸèƒ½æ¨¡å—ï¼š
   1. ğŸ›ï¸ éŸ³é¢‘é¢„å¤„ç† - å™ªå£°æ¶ˆé™¤å’Œä¿¡å·å¢å¼º
   2. ğŸ¼ éŸ³æºåˆ†ç¦» - åˆ†ç¦»éŸ³ä¹å’Œäººå£°
   3. ğŸ‘¥ è¯´è¯äººåˆ†ç¦» - å¤šè¯´è¯äººè¯†åˆ«åˆ†ç¦»
   4. ğŸ¯ äººå£°åŒ¹é… - åŸºäºå‚è€ƒéŸ³é¢‘çš„äººå£°åŒ¹é…
============================================================
âœ… å·²ä¸ºğŸ›ï¸ éŸ³é¢‘é¢„å¤„ç†é€‰æ‹©æ–‡ä»¶: lttgd.wav
ğŸµ Starting Audio Preprocessing Pipeline
============================================================
ERROR: C:\Users\zzy\miniconda3\envs\voice\Lib\inspect.py:1007: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0
  if ismodule(module) and hasattr(module, '__file__'):
ğŸ“ Loaded audio: lttgd.wav
   Sample rate: 16000 Hz
   Duration: 229.12 seconds
   Samples: 3665974

ğŸ” Original Audio Analysis
--------------------------------------------------
   Mean frequency: 2004.48 Hz
   Dominant frequency: 147.88 Hz
   Energy distribution:
     Low freq (0-1kHz): 88.9%
     Mid freq (1-4kHz): 8.2%
     High freq (4kHz+): 2.9%
ğŸ”§ Designed bandpass filter:
   Frequency range: 80.0-7000.0 Hz
   Normalized range: 0.010-0.875
   Filter order: 5
âœ… Applied bandpass filter (80-7000 Hz)

ğŸ§¹ Applying spectral subtraction denoising
   Alpha (over-subtraction): 1.5
   Beta (spectral floor): 0.1
âœ… Spectral subtraction completed

ğŸ” Processed Audio Analysis
--------------------------------------------------
   Mean frequency: 1835.39 Hz
   Dominant frequency: 147.88 Hz
   Energy distribution:
     Low freq (0-1kHz): 89.8%
     Mid freq (1-4kHz): 7.7%
     High freq (4kHz+): 2.4%
ğŸ’¾ Saved processed audio to: output/preprocessing\lttgd_preprocessed.wav
ğŸ“Š Visualization saved to: output/preprocessing\lttgd_analysis.png
ğŸ“„ Processing report saved to: output/preprocessing\lttgd_report.txt
âœ… Audio preprocessing pipeline completed successfully!
============================================================
âœ… éŸ³é¢‘é¢„å¤„ç†å®ŒæˆæˆåŠŸï¼
ğŸ“ è¾“å‡ºæ–‡ä»¶: output/preprocessing\lttgd_preprocessed.wav
ğŸ“‚ å·²æ‰“å¼€è¾“å‡ºæ–‡ä»¶å¤¹: output/preprocessing
âœ… å·²ä¸ºğŸ¼ éŸ³æºåˆ†ç¦»é€‰æ‹©æ–‡ä»¶: lttgd.wav
ğŸµ Starting Demucs Source Separation
==================================================
ğŸ“ Input file: lttgd.wav
ğŸ“‚ Output directory: output/demucs_output
ğŸ¤– Model: htdemucs
ğŸ’» Device: cpu
ğŸ¼ Stems: all (vocals, drums, bass, other)

ğŸ”„ Running Demucs separation...
Command: python -m demucs --name htdemucs --out output/demucs_output --device cpu C:/Users/zzy/Desktop/Courses/xinhaoyuxitong/voice_processing/input/lttgd.wav
âœ… Demucs separation completed successfully!
  ğŸ“„ Vocals: output/demucs_output\htdemucs\lttgd\vocals.wav
  ğŸ“„ Drums: output/demucs_output\htdemucs\lttgd\drums.wav
  ğŸ“„ Bass: output/demucs_output\htdemucs\lttgd\bass.wav
  ğŸ“„ Other: output/demucs_output\htdemucs\lttgd\other.wav

ğŸ” Analyzing separated audio files...
  Vocals:
    Duration: 229.12s
    RMS Energy: 0.1238
    Peak: 0.9901
    Dynamic Range: 18.1 dB
  Drums:
    Duration: 229.12s
    RMS Energy: 0.0140
    Peak: 0.7887
    Dynamic Range: 35.0 dB
  Bass:
    Duration: 229.12s
    RMS Energy: 0.0032
    Peak: 0.1067
    Dynamic Range: 30.4 dB
  Other:
    Duration: 229.12s
    RMS Energy: 0.0212
    Peak: 0.6735
    Dynamic Range: 30.0 dB
ğŸ“„ Separation report saved to: output/demucs_output\lttgd_separation_report.txt
âœ… éŸ³æºåˆ†ç¦»å®ŒæˆæˆåŠŸï¼
ğŸ“ åˆ†ç¦»çš„éŸ³è½¨: vocals, drums, bass, other
âœ… å·²ä¸ºğŸ‘¥ è¯´è¯äººåˆ†ç¦»é€‰æ‹©æ–‡ä»¶: vocals.wav
ğŸµ Starting Pyannote Speaker Separation
==================================================
âœ… Hugging Face authentication successful
ğŸ¤– Loading Pyannote speech separation pipeline...
ERROR: C:\Users\zzy\miniconda3\envs\voice\Lib\site-packages\speechbrain\utils\parameter_transfer.py:234: UserWarning: Requested Pretrainer collection using symlinks on Windows. This might not work; see `LocalStrategy` documentation. Consider unsetting `collect_in` in Pretrainer to avoid symlinking altogether.
  warnings.warn(
âœ… Pyannote pipeline loaded successfully on cuda
ğŸ“ Input file: vocals.wav
ğŸ“‚ Output directory: output/speaker_output
ğŸ”„ Loading audio file...
   Sample rate: 44100 Hz
   Duration: 229.12 seconds
   Channels: 2
ğŸ”„ Running speaker separation...
ERROR: C:\Users\zzy\miniconda3\envs\voice\Lib\site-packages\pyannote\audio\utils\reproducibility.py:74: ReproducibilityWarning: TensorFloat-32 (TF32) has been disabled as it might lead to reproducibility issues and lower accuracy.
It can be re-enabled by calling
   >>> import torch
   >>> torch.backends.cuda.matmul.allow_tf32 = True
   >>> torch.backends.cudnn.allow_tf32 = True
See https://github.com/pyannote/pyannote-audio/issues/1370 for more details.

  warnings.warn(
ERROR: C:\Users\zzy\miniconda3\envs\voice\Lib\site-packages\torch\nn\functional.py:5476: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\aten\src\ATen\native\transformers\cuda\sdp_utils.cpp:263.)
  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)
segmentation         â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 0:00:39
separations          â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 0:00:00
speaker_counting     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 0:00:00
embeddings           â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 0:00:12
discrete_diarization â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 0:00:00
ğŸ“„ Diarization saved to: output/speaker_output\vocals_diarization.rttm
ğŸ‘¥ Found 2 speakers: ['SPEAKER_00', 'SPEAKER_01']
  ğŸ’¾ SPEAKER_00: output/speaker_output\vocals_SPEAKER_00.wav
  ğŸ’¾ SPEAKER_01: output/speaker_output\vocals_SPEAKER_01.wav

ğŸ” Analyzing separated speaker files...
  SPEAKER_00:
    Duration: 229.50s
    RMS Energy: 0.4685
    Peak: 1.0000
  SPEAKER_01:
    Duration: 229.50s
    RMS Energy: 0.2547
    Peak: 1.0000
ğŸ“„ Speaker separation report saved to: output/speaker_output\vocals_speaker_report.txt
âœ… Pyannote speaker separation completed successfully!
âœ… è¯´è¯äººåˆ†ç¦»å®ŒæˆæˆåŠŸï¼
ğŸ‘¥ å‘ç°çš„è¯´è¯äºº: SPEAKER_00, SPEAKER_01
ğŸ“‚ å·²æ‰“å¼€è¾“å‡ºæ–‡ä»¶å¤¹: output/speaker_output
âœ… å·²é€‰æ‹©å‚è€ƒéŸ³é¢‘: SPEAKER_01_fixed.wav
âœ… å·²é€‰æ‹©å‚è€ƒéŸ³é¢‘: SPEAKER_01_fixed.wav
âœ… å·²é€‰æ‹©å‚è€ƒéŸ³é¢‘: lttgd_ref.wav
âœ… å·²é€‰æ‹©1ä¸ªå¾…åŒ¹é…éŸ³é¢‘æ–‡ä»¶
ğŸ¯ äººå£°åŒ¹é…å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¼€å§‹å¤„ç†ï¼
âœ… å·²é€‰æ‹©1ä¸ªå¾…åŒ¹é…éŸ³é¢‘æ–‡ä»¶
ğŸ¯ äººå£°åŒ¹é…å‡†å¤‡å°±ç»ªï¼Œå¯ä»¥å¼€å§‹å¤„ç†ï¼
ğŸµ Starting Voice Matching Analysis
============================================================
ğŸ“ Loading reference audio...
ğŸ“ Loaded: lttgd_ref.wav (12.76s)
ğŸ” Analyzing reference audio features...
  ğŸ” Extracting comprehensive features...
    âœ… Extracted 23 feature types

ğŸ‘¥ Analyzing 1 candidate audio files...

[1/1] Processing: SPEAKER_01_fixed
ğŸ“ Loaded: SPEAKER_01_fixed.wav (229.50s)
  ğŸ” Extracting comprehensive features...
    âœ… Extracted 23 feature types
âŒ å¤„ç†é”™è¯¯: Processing error: unsupported format string passed to numpy.ndarray.__format__
Traceback (most recent call last):
  File "C:\Users\zzy\Desktop\Courses\xinhaoyuxitong\voice_processing\gui\voice_processing_app.py", line 107, in run
    self.result = self.func(*self.args, **self.kwargs)
                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\zzy\Desktop\Courses\xinhaoyuxitong\voice_processing\modules\voice_matching\voice_matcher.py", line 416, in match_voices
    print(f"    ğŸ“Š Composite similarity score: {composite_score:.3f}")
                                               ^^^^^^^^^^^^^^^^^^^^^
TypeError: unsupported format string passed to numpy.ndarray.__format__